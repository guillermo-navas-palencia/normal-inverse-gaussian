\documentclass[10pt,a4paper,oneside]{article}

\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{bigints}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage[noblocks]{authblk}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{mathtools}
\usepackage{color}
\usepackage{listings}
\usepackage{fancyvrb}
\usepackage{float}
\usepackage{framed}
\usepackage{multirow}
%\usepackage{hyperref}
\usepackage{url}  % This makes \url work
\usepackage{multicol}
\usepackage{subcaption}
\setlength{\columnsep}{1cm}
\usepackage{pifont}
\usepackage{colortbl}
\usepackage{framed}
\usepackage{listings}
\usepackage{bm}
\usepackage{eurosym}
\usepackage{amssymb}% http://ctan.org/pkg/amssymb
\usepackage{suffix}
\usepackage{tikz}
\usepackage{bbm}
\usetikzlibrary{matrix}
\usepackage[customcolors]{hf-tikz}

\usepackage[toc,page]{appendix}

\newcommand{\cmark}{\ding{51}}%
%\floatname{algorithm}{Procedure}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\usepackage[a4paper,left=2cm,right=2cm,top=2.5cm,bottom=2.5cm]{geometry}
\usepackage[font=small]{caption}

%%enviroments for Theorems, propositions
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{problem}{Open Problem}[section]
\newtheorem{conjecture}{Conjecture}[section]
\newtheorem{example}[theorem]{Example}
\newenvironment{proof}{\noindent{\bf Proof:}}{\hfill$\square$}

\DeclareMathOperator{\arcsinh}{arcsinh}
\DeclareMathOperator{\erfc}{erfc}

\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}

\numberwithin{equation}{section}

\title{On the computation of the cumulative distribution function of the Normal Inverse Gaussian distribution}
\author{
 \normalsize  Guillermo Navas-Palencia\\
  \texttt{\normalsize  g.navas.palencia@gmail.com}
}

\date{\small \today}

\begin{document}
\maketitle

\abstract{Abstract}
%\tableofcontents
%\newpage
\section{Introduction}

Applications:
\begin{itemize}
\item Generalized Hyperbolic distribution \cite{Prause1999}
\item Variance-Gamma \cite{Madan1990}
\item NIG in Energy markets: \cite{Benth2004}
\item NIG in volatility modelling: \cite{Barndorff1997}
\end{itemize}

The use of the modified Bessel function of the second kind, here simply called modified Bessel function, will be omnipresent.


\section{Distribution properties}

REVIEW: \cite{Paolella2007}. A special type of mixture, called the variance-mean mixture of normals. It is defined as a mixture of normal distributions such that the mean and variance of the mixed distribution is in a special (affine-linear) relation. Consider $Z$ is a positive random variable following an incomplete Gaussian distribution, and $\mu$ and $\beta$ are constants. The variance-mean mixture distribution
\begin{equation}
Z \sim \mathcal{IG}(\delta \gamma, \gamma^2), \quad X \,|\, Z \sim \mathcal{N}(\mu + \beta Z, Z),
\end{equation}
where $\gamma = \sqrt{\alpha^2 - \beta^2}$. The domain of the parameters is
\begin{equation}
0 \le |\beta| < \alpha, \quad \mu \in \mathbb{R}, \quad \delta  > 0.
\end{equation}

Define $\omega = \sqrt{(x-\mu)^2 + \delta^2}$.

NOTES
\begin{itemize}
\item $\mu$: location parameter
\item Scale-invariant parameterization
\item Moment generating function
\item First four moments and reference to the paper of generalized hyperbolic distribution moments.
\item The family of generalized hyperbolic distributions is obtained by mixing normals using the generalized inverse Gaussian family of weights.
\item Parameterization options. Use of the parameterization dominating the literature.
\end{itemize}

\subsection{Density function}
The density function is given as
\begin{equation}
f(x; \alpha, \beta, \mu, \delta) = \frac{\alpha \delta}{\pi} \frac{K_1\left(\alpha\sqrt{\delta^2 + (x-\mu)^2}\right)}{\sqrt{\delta^2 + (x-\mu)^2}} e^{\delta \gamma + \beta(x-\mu)}
\end{equation}

Parameterization: Standard case $\mu = 0$ and $\delta = 1$. The parameters have the following interpretation: $\alpha$ is the tail heaviness, $\beta$ is the asymmetry or skewness, $\mu$ is the location parameter and $\delta$ the scale parameter. Where $\mu$ is the location of the density, $\beta$ is the skewness parameter, $\alpha$ measures the heaviness of the tails.

If the parameter $\beta \neq 0$, then the distribution will usually be skewed.

\subsection{Cumulative distribution function}\label{properties_cdf}
The cumulative distribution function is given by
\begin{equation}\label{integral_k1}
F(x; \alpha, \beta, \mu, \delta) = \frac{\alpha \delta e^{\delta \gamma}}{\pi} \int_{-\infty}^{x} \frac{K_1\left(\alpha\sqrt{\delta^2 + (t-\mu)^2}\right)}{\sqrt{\delta^2 + (t-\mu)^2}} e^{\beta(t-\mu)} \mathop{dt}
\end{equation}

\begin{equation}\label{integral_phi}
F(x; \alpha, \beta, \mu, \delta) = \frac{\delta}{\sqrt{2\pi}}\int_{0}^{\infty} \Phi\left(\frac{x - (\mu +\beta t)}{\sqrt{t}}\right) t^{-3/2} e^{-\frac{(\delta - \gamma t)^2}{2t}} \mathop{dt}
\end{equation}

Also denote the reflection formula
\begin{equation}\label{cdf_mirror}
\tilde{F}(x; \alpha, \beta, \mu, \delta) = 1- F(-x; \alpha, -\beta, -\mu, \delta),
\end{equation}
which follows from the reflection formula of $\Phi(x) = 1 - \Phi(-x)$.

\subsubsection{Alternative integral representations}
We obtain the following alternative integral representations in terms other special functions. More interestingly, we derive an integral representation in terms of elementary functions. Although these representations have restrictions on the sign of $x-\mu$, the use of the reflection formula \eqref{cdf_mirror} permits the computation on the whole domain.

\begin{proposition} An incomplete Laplace-type integral representation in terms of modified Bessel function $K_0(x)$ is given by
\begin{equation}\label{integral_k0}
F(x; \alpha, \beta, \mu, \delta) = \frac{\sqrt{2}\delta e^{\delta \gamma}}{\pi}\int_{\beta / \sqrt{2}}^{\infty} e^{\sqrt{2}(x-\mu)t} K_0\left(\sqrt{2\left( (x-\mu)^2 + \delta^2\right)} \sqrt{\frac{\gamma^2}{2} + t^2}\right) \mathop{dt}, \quad x - \mu < 0.
\end{equation}
\end{proposition}
\begin{proof}
Consider the integral representation of the function $\Phi\left(\frac{x-\mu}{\sqrt{t}} -\beta \sqrt{t} \right)$
\begin{equation*}
\Phi\left(\frac{x-\mu}{\sqrt{t}} -\beta \sqrt{t} \right) = \sqrt{\frac{t}{\pi}} e^{-\frac{(x-\mu)^2}{2t}}\int_{\beta/\sqrt{2}}^{\infty} e^{-(tu^2 - \sqrt{2}(x-\mu) u)} \mathop{du}.
\end{equation*}
Replacing in \eqref{integral_phi} and interchanging the order of integration, we obtain
\begin{equation*}
F(x; \alpha, \beta, \mu, \delta) = \frac{\delta e^{\delta \gamma}}{\sqrt{2}\pi} \int_{\beta/\sqrt{2}}^{\infty} e^{\sqrt{2}(x-\mu) u} \int_{0}^{\infty} t^{-1} e^{-\frac{\left((x-\mu)^2 + \delta^2\right)}{2t} - \left(\frac{\gamma^2}{2} + u^2\right)t} \mathop{dt} \mathop{du}.
\end{equation*}
The observation that the inner integral can be represented in terms of the modified Bessel function $K_0(x)$
\begin{equation*}
\int_{0}^{\infty} t^{-1} e^{-\frac{\left((x-\mu)^2 + \delta^2\right)}{2t} - \left(\frac{\gamma^2}{2} + u^2\right)t} \mathop{dt} = 2 K_0\left(2\sqrt{\frac{(x-\mu)^2 + \delta^2}{2}} \sqrt{\frac{\gamma^2}{2} + t^2}\right).
\end{equation*}
\end{proof}

\begin{proposition}
An integral representation of the cumulative distribution function in terms of elementary functions is given by
\begin{equation}\label{integral_sine_transform}
F(x; \alpha, \beta, \mu, \delta) = 1 - \frac{e^{\delta \gamma}}{\pi}\int_0^{\infty} \frac{t e^{-(x-\mu)\left(\sqrt{t^2 + \alpha^2} - \beta\right)}}{\sqrt{t^2 + \alpha^2}\left(\sqrt{t^2 + \alpha^2} - \beta\right)}\sin(\delta t)\mathop{dt}, \quad x-\mu > 0.
\end{equation}
\end{proposition}
\begin{proof}
Consider the integral representation \eqref{integral_k1}. Then, we replace the term involving $K_1(x)$ by its sine transform \cite[\S 2.4]{Bateman1954}
\begin{equation*}
\frac{K_1(\alpha \sqrt{t^2 + \delta^2})}{\sqrt{t^2 + \delta^2}} = \frac{1}{\alpha\delta}\int_0^{\infty} \frac{z e^{-t\sqrt{z^2 + \alpha^2}}}{\sqrt{z^2 + \alpha^2}} \sin(\delta z) \mathop{dz},
\end{equation*}
valid for $t \ge 0$. Replacing in \eqref{integral_k1} and interchanging the order of integration, we have
\begin{align*}
F(x; \alpha, \beta, \mu, \delta) &= 1 - \frac{\alpha \delta e^{\delta \gamma}}{\pi}\frac{1}{\alpha\delta}\int_0^{\infty} \frac{z \sin(\delta z)}{\sqrt{z^2 + \alpha^2}}  \int_{x-\mu}^{\infty} e^{-t\sqrt{z^2 + \alpha^2} + \beta t} \mathop{dt} \mathop{dz}\\
&= 1 - \frac{e^{\delta \gamma}}{\pi}\int_0^{\infty} \frac{z \sin(\delta z)}{\sqrt{z^2 + \alpha^2}}  \frac{e^{-(x-\mu)\left(\sqrt{z^2 + \alpha^2} - \beta\right)}}{\sqrt{z^2 + \alpha^2} - \beta} \mathop{dz}
\end{align*}
where the inner integral converges for $x-\mu > 0$.
\end{proof}

Analogously, we obtain an integral representation in terms of the exponential integral $E_1(x)$ using the cosine transform of the modified Bessel function.
\begin{proposition}
An integral representation of the cumulative distribution function in terms of the exponential integral $E_1(x)$ is given by
\begin{equation}
F(x; \alpha, \beta, \mu, \delta) = 1 - \frac{\delta e^{\delta \gamma}}{\pi}\int_0^{\infty} E_1\left((x-\mu)(\sqrt{t^2 + \alpha^2} - \beta)\right) \cos(\delta t) \mathop{dt}, \quad x-\mu > 0.
\end{equation}
\end{proposition}
\begin{proof}
This result can be derived from the sine transform in \eqref{integral_sine_transform} using integration by parts. Instead, we can use the cosine transform \cite[\S 1.4]{Bateman1954}
\begin{equation*}
\frac{K_1\left(\alpha\sqrt{\delta^2 + t^2}\right)}{\sqrt{\delta^2 + t^2}} = \frac{1}{\alpha t}\int_0^{\infty} e^{-t\sqrt{z^2 + \alpha^2}} \cos(\delta z) \mathop{dz}.
\end{equation*}
Thus,
\begin{equation*}
F(x; \alpha, \beta, \mu, \delta) = 1 - \frac{\alpha \delta e^{\delta \gamma}}{\pi}\int_{x-\mu}^{\infty} \frac{e^{\beta t}}{\alpha t}\int_0^{\infty} e^{-t\sqrt{z^2 + \alpha^2}} \cos(\delta z) \mathop{dz} \mathop{dt},
\end{equation*}
where the inner integral is expressible in closed form in terms of the exponential integral $E_1(x)$
\begin{equation*}
\int_{x-\mu}^{\infty}\frac{1}{t}e^{-(\sqrt{z^2 + \alpha^2} - \beta)t} \mathop{dt} = E_1\left((x-\mu)(\sqrt{z^2 + \alpha^2} - \beta)\right).
\end{equation*}
\end{proof}

Moreover, an integral representation whose integrand decays double-exponentially is obtained using the transformation described in \cite[\S 42.4]{Temme2015}. First, we write $\beta = \alpha \tanh(\theta)$, valid since $|\beta| < \alpha$. Substituting in \eqref{integral_k1} the term $x-\mu = \delta \sinh(\theta + u)$, we obtain
\begin{equation}
F(x; \alpha, \beta, \mu, \delta) = \frac{\alpha \delta e^{\delta \gamma}}{\pi} \int_{-\infty}^{\tau} K_1 \left(\alpha \delta \cosh(\theta + u)\right) e^{\beta \delta \sinh(\theta + u)} \mathop{du},
\end{equation}
where
\begin{equation}
\tau = \arcsinh\left(\frac{x - \mu}{\delta}\right) - \theta.
\end{equation}

To conclude, a discussion on the numerical integration methods for effective computation of the previous integrals is presented in Section \ref{section_numerical_integration}.

%\subsection{Moments and cumulants}
%
%\begin{equation}
%\mathbb{E}[X^m] = \frac{\alpha \delta}{\pi} \int_{-\infty}^{\infty} t^m\frac{K_1\left(\alpha\sqrt{\delta^2 + (t-\mu)^2}\right)}{\sqrt{\delta^2 + (t-\mu)^2}} e^{\delta \gamma + \beta(t-\mu)} \mathop{dt}.
%\end{equation}
%
%\begin{equation}
%\mathbb{E}[X^m] = \frac{\alpha \delta}{\pi} e^{\delta \gamma - \beta \mu} \sum_{k=0}^{\infty} \frac{\beta^k}{k!}\int_{-\infty}^{\infty} (t-\mu)^{m+k}\frac{K_1\left(\alpha\sqrt{\delta^2 + t^2}\right)}{\sqrt{\delta^2 + t^2}} \mathop{dt}.
%\end{equation}
%Use binomial theorem, and compute coefficients recursively (binomial sum of Bessel functions). Treat special case $\mu = 0$ and $\beta=0$.

\section{Methods of computation}
In this Section, we describe the methods used for efficient computation of the CDF for the general case and various special cases, $\beta = 0$ and $x=\mu$, respectively. In particular, we explore series expansions, asymptotic expansions, uniform asymptotic expansions and numerical integration. We emphasize that many of the techniques and numerical methods introduced in the sections devoted to the two special cases shall also be used to develop expansions of the general case in Section \ref{section_general_case}.


\subsection{Special case $\beta = 0$}\label{section_special_case_beta_0}
The case $\beta = 0$ corresponds to the symmetric case. The symmetric NIG distribution has been widely used in financial modelling, for example for pricing collateralized default obligations (CDO) \cite{Kalemanova2007} and market risk \cite{Prause1999} where symmetric distributions are employed for modelling macro-economical factors as an fat-tailed alternative to the normal distribution.



\subsubsection{Expansions $|x-\mu| \to 0$}
For developing a series expansion for the case $|x-\mu| \to 0$, we start from the integral representation in \eqref{integral_phi}, after expanding the square
\begin{equation}\label{integral_phi2}
F(x; \alpha, 0, \mu, \delta) = \frac{\delta e^{\delta \alpha}}{\sqrt{2\pi}} \int_0^{\infty} \Phi\left(\frac{x - \mu}{\sqrt{t}}\right) t^{-3/2} e^{-\frac{\delta^2}{2t} - \frac{\alpha^2}{2}t} \mathop{dt}.
\end{equation}
We proceed expanding the term $\Phi\left(\frac{x-\mu}{\sqrt{t}}\right)$, by using the two well-known absolutely convergent series expansions of $\Phi(x)$ \cite[\S 2]{Lebedev1972}
\begin{equation}\label{phi_expansion_1}
\Phi(x) = \frac{1}{2} + \frac{1}{\sqrt{2\pi}}\sum_{k=0}^{\infty} \frac{(-1)^k x^{2k + 1}}{2^k k! (2k+1)},
\end{equation}
and
\begin{equation}\label{phi_expansion_2}
\Phi(x) = \frac{1}{2} + \frac{e^{-x^2 / 2}}{\sqrt{2\pi}}\sum_{k=0}^{\infty} \frac{x^{2k+1}}{(2k + 1)!!}.
\end{equation}
If we choose the expansion \eqref{phi_expansion_1} and interchange the order of integration and summation, the resulting integral has the form
\begin{equation}\label{phi_expansion_integral_xmu_b0_alternating}
F(x; \alpha, 0, \mu, \delta) = \frac{\delta e^{\delta \alpha}}{\sqrt{2\pi}} \sum_{k=0}^{\infty} \frac{(-1)^k (x-\mu)^{2k + 1}}{2^k k! (2k + 1)}\int_0^{\infty} t^{-k-2} e^{-\frac{\delta^2}{2t} - \frac{\alpha^2}{2}t} \mathop{dt},
\end{equation}
where the integral has a closed-form in terms of the modified Bessel function. In general,
\begin{equation}\label{bessel_integral}
\int_0^{\infty} t^{\lambda - 1}e^{-a/t - zt} \mathop{dt} = 2\left(\frac{\alpha}{z}\right)^{\lambda/2} K_{\lambda}(2\sqrt{\alpha z}).
\end{equation}
Inserting \eqref{bessel_integral} in \eqref{phi_expansion_integral_xmu_b0_alternating} and rearranging terms, we obtain the the alternating series
\begin{equation}\label{expansion_xmu_b0_alternating}
F(x; \alpha, 0, \mu, \delta) = \frac{1}{2} + \frac{\delta e^{\delta \alpha}}{\pi}\sum_{k=0}^{\infty} \frac{(-1)^k (x-\mu)^{2k+1}}{2^k k! (2k + 1)} \left(\frac{\alpha}{\delta}\right)^{k+1}K_{k+1}(\alpha \delta).
\end{equation}
Moreover, to obtain a similar series with positive terms, we choose the expansion of $\Phi(x)$ in \eqref{phi_expansion_2}, yielding
\begin{equation}\label{expansion_xmu_b0_positive}
F(x; \alpha, 0, \mu, \delta) = \frac{1}{2} + \frac{\delta e^{\delta \alpha}} {\pi}\sum_{k=0}^{\infty} \frac{(x-\mu)^{2k+1}}{(2k +1)!!} \left(\frac{\alpha}{\omega}\right)^{k+1}K_{k+1}(\alpha \omega).
\end{equation}

Note that the series expansions \eqref{expansion_xmu_b0_alternating} and \eqref{expansion_xmu_b0_positive} can be written as a truncated series with the corresponding remainder term. For example, truncating the series \eqref{expansion_xmu_b0_positive} at $N$, we can write
\begin{equation}\label{expansion_xmu_b0_positive_error_term}
\sum_{k=0}^{\infty} T_k = \sum_{k=0}^{N-1} T_k + \sum_{k=N}^{\infty}T_k, \quad T_k = \left(\frac{(x-\mu)^2 \alpha}{\omega}\right)^k \frac{K_{k+1}(\alpha \omega)}{(2k +1)!!}.
\end{equation}
Thus, one has the series with remainder term $R_N = \sum_{k=N}^{\infty}T_k$
\begin{equation}\label{expansion_xmu_b0_positive_with_remainder}
F(x; \alpha, 0, \mu, \delta) = \frac{1}{2} + \frac{\delta e^{\delta \alpha}}{\pi}\frac{(x-\mu)\alpha}{\omega}\left(\sum_{k=0}^{N-1}T_k + R_N\right).
\end{equation}

For a rigorous evaluation of error bounds given a number of terms $N$, it is convenient to calculate an upper bound for $R_N$ in \eqref{expansion_xmu_b0_positive_error_term}. We can, for example, bound $R_N$ by comparison with a geometric series
\begin{equation}
\left|R_N \right| \le \frac{|T_N|}{1 - C}, \quad C = \left|\frac{T_{N+1}}{T_N}\right|
\end{equation}
iff $C < 1$, where $T_N$ is the first omitted term in the expansion. The following lemma provides an upper bound for $K_{\nu+1}(x)$, required for a posterior derivation of an upper bound for the term $T_N$.
\begin{lemma}\label{lemma_1}
For $x \ge 0$ and $\nu \ge -\frac{1}{2}$ we have
\begin{equation}
K_{\nu + 1}(x) < \frac{\Gamma(\nu + 1)2^{\nu}}{x^{\nu + 1}}.
\end{equation}
\end{lemma}
\begin{proof}
The proof reduces to combining the uniform bound in \cite{Gaunt2016}
\begin{equation}
x K_{\nu + 1}(x) I_{\nu}(x) \le 1.
\end{equation}
with the lower bound \cite{Luke1972}
\begin{equation}
\left(\frac{x}{2}\right)^{\nu}\frac{1}{\Gamma(\nu + 1)} < I_{\nu}(x).
\end{equation}
Then, it follows that
\begin{equation}
K_{\nu + 1}(x) \le \frac{1}{x I_{\nu}(x)} < \frac{\Gamma(\nu + 1)2^{\nu}}{x^{\nu + 1}}.
\end{equation}
\end{proof}

\begin{theorem}\label{theorem_expansion_xmu_b0_postivie_remainder}
Given $\alpha > 0$, $\omega > 0$, $x-\mu \in \mathbb{R}$ and $N \in \mathbb{N}$, the remainder term in \eqref{expansion_xmu_b0_positive_with_remainder} satisfies
\begin{equation}\label{bound_remainder_xmu_b0_positive}
R_N \le \frac{|T_N|}{1 - C},
\end{equation}
where
\begin{equation}\label{bound_TN_xmu_b0_positive}
T_N < \frac{1}{2\alpha\omega}\left(\frac{x-\mu}{\omega}\right)^{2N} \sqrt{\frac{\pi}{N + 1/2}}.
\end{equation}
and
\begin{equation}
C < \left(\frac{x-\mu}{\omega}\right)^2 \frac{N + 3/2 + \sqrt{(N + 3/2)^2 + (\alpha\omega)^2}}{2N + 3}.
\end{equation}
\end{theorem}

\begin{proof}
The use of Lemma \ref{lemma_1} gives
\begin{align*}
T_N &= \left(\frac{(x-\mu)^2 \alpha}{\omega}\right)^N \frac{K_{N+1}(\alpha \omega)}{(2N +1)!!}\\
&<  \left(\frac{(x-\mu)^2 \alpha}{\omega}\right)^N \frac{\Gamma(N + 1)2^N}{(\alpha\omega)^{N + 1}(2N +1)!!}\\
&= \frac{1}{\alpha\omega}\left(\frac{x-\mu}{\omega}\right)^{2N} \frac{(N! 2^N)^2}{(2N + 1)!}.
\end{align*}
An upper bound for the ratio of factorials in the previous inequality is given by
\begin{equation*}
\frac{(N! 2^N)^2}{(2N + 1)!} = \frac{\sqrt{\pi}}{2}\frac{\Gamma(N+1)}{\Gamma(N + 3/2)} \le \frac{1}{2}\sqrt{\frac{\pi}{N + 1/2}},
\end{equation*}
where we use the fact that $\Gamma(N + 3/2) = (N + 1/2) \Gamma(N + 1/2)$ and the upper bound of the ratio of gamma functions \cite{Wendel1948}
\begin{equation}
\frac{\Gamma(x + 1)}{\Gamma(x+s)} \le (x + s)^{1-s}, \quad s \in (0, 1).
\end{equation}
Thus, the following bound for $T_N$ holds
\begin{equation}
T_N < \frac{1}{2\alpha\omega}\left(\frac{x-\mu}{\omega}\right)^{2N} \sqrt{\frac{\pi}{N + 1/2}}.
\end{equation}

For the ratio $C$, an explicit formula in terms of the ratio of modified Bessel functions is
\begin{equation}
C = \frac{T_{N+1}}{T_N} = \frac{(x-\mu)^2 \alpha}{\omega (2N + 3)} \frac{K_{N+2}(\alpha\omega)}{K_{N+1}(\alpha\omega)}.
\end{equation}
The ratio can be bounded using a sharp bound for the ratio of modified Bessel functions \cite{Segura2023}, yielding
\begin{equation}
\frac{K_{N+2}(\alpha\omega)}{K_{N+1}(\alpha\omega)} < \frac{N + 3/2 + \sqrt{(N + 3/2)^2 + (\alpha\omega)^2}}{\alpha \omega}.
\end{equation}
Then, we have
\begin{equation*}
C < \left(\frac{x-\mu}{\omega}\right)^2 \frac{N + 3/2 + \sqrt{(N + 3/2)^2 + (\alpha\omega)^2}}{2N + 3}.
\end{equation*}
\end{proof}

To study the regime of applicability for the expansion, we can estimate the required number of terms $N$ equating the bound of $T_N$ in \eqref{bound_TN_xmu_b0_positive} times the normalizing factor with the requested absolute error $\epsilon$ and solving for $N$, which gives
\begin{equation}\label{N_expansion_xmu_b0_positive}
N \approx -\frac{\Re(W_{-1}(D))}{4 \log(A)} + \frac{1}{2}, \quad A = \frac{x-\mu}{\omega}, \quad B = \frac{A\delta e^{\delta \alpha}}{2\omega\pi}, \quad C = \frac{\epsilon^2}{B^2 \pi}, \quad D = -\frac{4 \log(A)}{C A^2}
\end{equation}
where $W_k(x)$ denotes the Lambert $W$ function \cite[\S 4.13]{NIST:DLMF}. The branch $k=-1$ is used to obtain the maximum real $N$. Note that since $A < 1$ by definition, $D > 0$. When $C A^2$ is tiny, $W_{-1}(D)$ can be approximated as $\Re(W_{-1}(D)) \sim \log(D) - \log(\log(D))$ using the first two terms of the asymptotic expansion in \cite[\S 4.13.10]{NIST:DLMF}.

The previous analysis performed on the expansion \eqref{expansion_xmu_b0_positive} is repeated for the alternating expansion \eqref{expansion_xmu_b0_alternating}. The main results are summarized below for the purpose of brevity. The expansion \eqref{expansion_xmu_b0_alternating} rewritten including the remainder term follows
\begin{equation}
F(x; \alpha, 0, \mu, \delta) = \frac{1}{2} + \frac{(x-\mu)\alpha e^{\delta \alpha}}{\pi} \left( \sum_{k=0}^{N-1} T_k + R_N\right),  \quad T_k = \left(-\frac{(x-\mu)^2 \alpha}{\delta}\right)^k \frac{K_{k+1}(\alpha \delta)}{2^k k! (2k + 1)}.
\end{equation}
The last omitted term $T_N$ satisfies\footnote{The corresponding upper bound for $C$ can be computed straightforwardly following the procedure described in Theorem \ref{theorem_expansion_xmu_b0_postivie_remainder}.}
\begin{equation}
|T_N| < \frac{1}{\alpha \delta} \left(\frac{x-\mu}{\delta}\right)^{2N} \frac{1}{2N + 1},
\end{equation} 
and the number of terms $N$ can be determined employing the Lambert $W$ function for a given error $\epsilon$
\begin{equation}
N \approx \frac{\Re(W_{-1}(D)) + \log(A)}{2 \log(A)}, \quad A = \frac{x-\mu}{\delta}, \quad B = \frac{A e^{\delta \alpha}}{\pi}, \quad C = \frac{\epsilon}{B}, \quad D = -\frac{\log(A)}{CA}.
\end{equation}

Now we are in position to compare both series and their respective domains of applicability. A first important observation is that the alternating series \eqref{expansion_xmu_b0_alternating} does not converge when $|x - \mu| > \delta$, and the number of terms $N$ increases rapidly when $|x - \mu| \sim \delta$. In contrast, the series \eqref{expansion_xmu_b0_positive} is absolutely convergent. The convergence of the latter can be reliably assessed applying to $T_k$ in \eqref{expansion_xmu_b0_positive_error_term} the asymptotic estimates of $K_{k+1}(\alpha\omega)$ for $\alpha \omega \to 0$ and $\alpha \omega \to \infty$, \eqref{besselk_x_to_0} and \eqref{besselk_x_to_inf}, respectively:
\begin{align*}
T_k &\sim \frac{\sqrt{\pi}}{2\alpha\omega} \left(\frac{x-\mu}{\omega}\right)^{2k}\frac{\Gamma(k + 1)}{\Gamma(k + 3/2)}, & \alpha\omega \to 0,\\
T_k &\sim \sqrt{\frac{\pi}{2\alpha \omega}} \left(\frac{(x-\mu)^2\alpha}{\omega}\right)^k \frac{e^{-\alpha \omega}}{(2k + 1)!!}, &\alpha\omega \to \infty.
\end{align*}
The asymptotic estimates of $T_k$ show that the series expansion \eqref{expansion_xmu_b0_positive} is slowly convergent when
\begin{equation*}
\left(\frac{x-\mu}{\omega}\right)^2 \to 1 \Longleftrightarrow \delta \to 0,
\end{equation*}
and the ratio of convergence improves when $\delta \to \infty$, then it can be viewed as an asymptotic expansion for large $\delta$. For $k \to \infty$, $T_k$ follows the asymptotic behaviour
\begin{equation*}
T_k \sim \frac{1}{\alpha\omega}\left(\frac{x-\mu}{\omega}\right)^{2k}\sqrt{\frac{\pi}{e}}\frac{1}{\sqrt{4k + 2}}\left(\frac{2k + 2}{2k + 1}\right)^{k + \frac{1}{2}}, \quad k \to \infty,
\end{equation*}
where we use the asymptotic estimate of modified Bessel function for large order \eqref{besselk_order_to_inf} and apply Stirling's approximation for the double factorial. It remains to analyze the accuracy of the bound in \eqref{bound_remainder_xmu_b0_positive} for different parameters. Table \ref{table_bound_remainder_xmu_b0_positive} shows the effectiveness of the bound \eqref{bound_remainder_xmu_b0_positive} after estimating $N$ to achieve machine-precision using \eqref{N_expansion_xmu_b0_positive}. For small values of $\alpha\omega$ the bound is sharp, but it is conservative for larger values, precisely where the rate of convergence improves. As a remark, the estimation of $N$ for large $\alpha\omega$ can be enhanced by selecting $N$ using the asymptotic estimate for $\alpha\omega \to \infty$ via binary search. Although, the bound might overestimate $N$ for some parameters, the main purpose of the estimation of $N$ using \eqref{N_expansion_xmu_b0_positive} is to decide whether the series expansion should be selected as the method of computation given a certain parameter region (see Section \ref{subsection_implementation}). Table \ref{table_bound_remainder_xmu_b0_positive} also shows that for small $\delta$ and $\alpha\omega$, the required number of terms makes the series expansion impractical. In the next section, we present a convergence acceleration method to obtain a rapidly convergent series for these cases.

\begin{table}[H]
	\centering
	\scalebox{0.9}{
\begin{tabular}{ccccc|ccc}
\hline
$x$ & $\alpha$ & $\mu$ & $\delta$ & $\alpha\omega$ & $N$ \eqref{N_expansion_xmu_b0_positive} &  $R_N$ & Bound \eqref{bound_remainder_xmu_b0_positive}\\
\hline
	1 & 5 & 1/4 & 1 & 6.25 & 42 & $8.8\cdot 10^{-19}$ & $1.1\cdot 10^{-18}$\\
	1/2 & 1/3 & 1/4 & 1/10 & 0.09 & 236 & $2.9\cdot 10^{-17}$ & $2.9\cdot 10^{-17}$\\
    1/3 & 10 & 1/5 & 1/50 & 1.35 & 1,494 & $2.1\cdot 10^{-16}$ & $2.2\cdot 10^{-16}$\\
    1 & 10 & 1/5 & 5 & 50.64 &  25 & $1.9\cdot 10^{-29}$ & $4.0\cdot 10^{-21}$\\
    3 & 10 & 1/5 & 10 & 103.85 & 53 & $2.4\cdot 10^{-36}$ & $1.4\cdot 10^{-19}$\\
    10 & 1/10 & 1/5 & 10 & 1 & 53 & $3.8\cdot 10^{-18}$ & $3.9\cdot 10^{-18}$\\
	\hline
	\end{tabular}}
	\caption{The remainder of the series expansion  \eqref{expansion_xmu_b0_positive} and bound \eqref{bound_remainder_xmu_b0_positive}, estimating $N$ using \eqref{N_expansion_xmu_b0_positive} to achieve machine precision.}
	\label{table_bound_remainder_xmu_b0_positive}
\end{table}

\subsubsection{Convergence acceleration of the expansion $|x-\mu| \to 0$}
Table \ref{table_bound_remainder_xmu_b0_positive} showed that for small values of $\delta$ and $\alpha \omega$ the required number of terms grows considerably, thereby, resorting to numerical integration (see Section \ref{section_numerical_integration}) might be a more efficient approach. Alternatively, a common technique to reduce the number of terms of slowly convergent series is to use series acceleration methods (Shank's transformation and Levin-type transformations among others \cite{Gil2007}). 
Attempts to use Shank's transformation were unsuccessful; we did not observe a significant reduction in $N$ while achieving only around ten correct digits systematically for all cases. In addition, a major drawback is that Shank's acceleration requires higher-precision arithmetic to compensate for cancellation effects, which makes us discard this option for an implementation in double-precision arithmetic. 

In the following, we investigate the use of exponentially improved asymptotic expansions. When the information about the remainder is available, this technique consists of re-expanding the remainder, obtaining an expansion exhibiting faster convergence. For further details, we refer to \cite[\S 14]{Olver1997}. Consider the convergent series expansion in \eqref{expansion_xmu_b0_positive_error_term}
\begin{equation}
F(x;\alpha, 0, \mu, \delta) = \frac{1}{2} + \frac{\delta e^{\delta \alpha}}{\pi} \frac{(x-\mu)\alpha}{\omega} \left(\sum_{k=0}^{N-1} T_k + \sum_{k=N}^{\infty} T_k\right),
\end{equation}
where
\begin{equation}
T_k = \frac{K_{k+1}(\alpha\omega)}{(2k + 1)!!} z^k, \quad z = \frac{(x-\mu)^2 \alpha}{\omega}.
\end{equation}
and remainder $R_N = \sum_{k=N}^{\infty} T_k$. An integral representation of $R_N$ can be obtained using Basset's integral \cite[\S 10.32.11]{NIST:DLMF} representation of the modified Bessel function
\begin{equation}\label{basset_integral}
K_{k+1}(\alpha\omega) = \frac{\Gamma(k + 3/2)}{\sqrt{\pi}}\left(\frac{2\alpha}{\omega}\right)^{k+1} \int_0^{\infty} \frac{\cos(\omega t)}{(t^2 + \alpha^2)^{k + 3/2}} \mathop{dt}.
\end{equation}
Basset's integral is chosen to transform the term $\alpha\omega$ into $\alpha/\omega$. Thus, it follows that inserting \eqref{basset_integral} into the remainder in \eqref{expansion_xmu_b0_positive_error_term}, we have an integral representation of $R_N$
\begin{align}\label{convergent_remainder_integral}
R_N &= \frac{1}{\sqrt{\pi}} \left(\frac{2\alpha}{\omega}\right) \int_0^{\infty} \frac{\cos(\omega t)}{(t^2 + \alpha^2)^{3/2}} \left[\sum_{k=N}^{\infty} \left(\frac{2z\alpha}{\omega (t^2 + \alpha^2)}\right)^k \frac{\Gamma(k + 3/2)}{(2k + 1)!!}\right] \mathop{dt}\nonumber\\
&= C \int_0^{\infty} \frac{\cos(\omega t)}{(t^2 + \alpha^2)^{N + 3/2}} \frac{1}{\left(2 - \frac{m}{t^2+ \alpha^2}\right)} \mathop{dt}.
\end{align}
where, for the purpose of brevity, we use
\begin{equation}
m = \frac{2z\alpha}{\omega} = 2\left(\frac{(x-\mu)\alpha}{\omega}\right)^2,  \quad C = \frac{2}{\sqrt{\pi}} \left(\frac{2\alpha}{\omega}\right)\frac{\Gamma(N + 3/2)}{(2N + 1)!!} m^N.
\end{equation}

Now, we expand the term $\cos(\omega t)$, recall that $\omega = \sqrt{\delta^2 + (x-\mu)^2}$, yielding
\begin{equation}\label{convergent_remainder_series_integral}
R_N = C \sum_{k=0}^{\infty} \frac{(-1)^k \omega^{2k}}{(2k)!} \int_0^{\infty} \frac{t^{2k}}{(t^2 + \alpha^2)^{N + 3/2}} \frac{1}{\left(2 - \frac{m}{t^2+ \alpha^2}\right)} \mathop{dt},
\end{equation}
and note that the integrals above converge for $k \le N$. Next, after various iterations with the assistance of Mathematica \cite{Mathematica}, we arrive to a closed-form expression for the previous integral in terms of the Gauss hypergeometric function $_2F_1(a, b; c; z)$
\begin{equation}\label{convergent_remainder_inner_integral}
\int_0^{\infty} \frac{t^{2k}}{(t^2 + \alpha^2)^{N + 3/2}} \frac{1}{\left(2 - \frac{m}{t^2+ \alpha^2}\right)} \mathop{dt} = P_k + Q_k,
\end{equation}
with
\begin{align}
P_k &= \frac{2^{N-2}\alpha^{2(k - N - 1)} \Gamma(N + 1 - k) \Gamma(k - 1/2)}{\sqrt{\pi} (2N + 1)!!} \, _2F_1\left(1, N + 1 - k; \frac{3}{2} -k, 1 - \frac{m}{2\alpha^2}\right),\\
Q_k &= \frac{2^{N-1-k}(2\alpha^2 - m)^{k - 1/2} \pi \sec(k\pi)}{m^{N + 1/2}}.
\end{align}

The Gauss hypergeometric function is defined by the hypergeometric series
\begin{equation*}
_2F_1(a, b; c; z) = \sum_{k=0}^{\infty} \frac{(a)_k (b)_k}{(c)_k k!} z^k,
\end{equation*}
where $(a)_k = \Gamma(a+k) / \Gamma(a)$ is the Pochhammer symbol or rising factorial. The series is defined on the disk $|z| < 1$, and by analytic continuation with respect to $z$ elsewhere. Subsequently, substituting \eqref{convergent_remainder_inner_integral} in \eqref{convergent_remainder_series_integral}, we write $R_N$ as the sum of two series $R_N  = S_P + S_Q$ given by
\begin{equation}\label{convergent_remainder_series_P}
S_P = \frac{(2m)^N }{\alpha^{2N + 1} \omega\pi} \frac{\Gamma(N + 3/2)}{(2N + 1)!! (2N - 1)!!} \sum_{k=0}^{N} \frac{(-1)^k (\alpha\omega)^{2k}}{(2k)!} \Gamma(N + 1 - k) \Gamma(k - 1/2) \, _2F_1\left(1, N + 1 - k; \frac{3}{2} -k, 1 - \frac{m}{2\alpha^2}\right)
\end{equation}
and 
\begin{align}
S_Q &= C \frac{2^{N-1}}{m^{N + 1/2}\sqrt{2\alpha^2 - m}} \pi \sum_{k=0}^{\infty} \frac{(-1)^k}{(2k)!} \left(\frac{\omega^2(2\alpha^2 - m)}{2}\right)^k \sec(k\pi)\nonumber\\
&= \frac{\Gamma(N + 3/2) 2^{N+1}}{(2N + 1)!!} \frac{\alpha}{\omega}\sqrt{\frac{\pi}{m(2\alpha^2 - m)}}\cosh\left(\sqrt{\frac{\omega^2 (2\alpha^2 - m)}{2}}\right).
\end{align}
The sum $S_P$ is terminating at $k=N$ due to the term $\Gamma(N + 1 - k)$ in the series. Thus, the resulting series to compute $F(x; \alpha, 0, \mu, \delta)$ is
\begin{equation}\label{convergent_accelerated_series_xmu_b0_positive}
F(x;\alpha, 0, \mu, \delta) = \frac{1}{2} + \frac{\delta e^{\delta \alpha}}{\pi} \frac{(x-\mu)\alpha}{\omega} \left(\sum_{k=0}^{N-1} T_k + S_P + S_Q\right).
\end{equation}
Next, we focus on the determination of the optimal $N$ for a desired precision $\epsilon$. The smallest term in $S_P$ occurs when $k=N$, corresponding to
\begin{equation}
S_P = \frac{(-1)^N (\alpha\omega)^{2N}}{(2N)!} \Gamma(N - 1/2) \, _2F_1\left(1, 1; \frac{3}{2} -N, 1 - \frac{m}{2\alpha^2}\right).
\end{equation}
Moreover, inspecting the argument of $_2F_1$ in \eqref{convergent_remainder_series_P},
\begin{equation}
1 - \frac{m}{2\alpha^2} = 1 - \left(\frac{x-\mu}{\omega}\right)^2 < 1,
\end{equation}
we see that for $\alpha \omega \to 0$, $\delta \to 0$, the argument is close to 1. Therefore, for the parameter regime of interest, the last term can be effectively approximated taking the limit $\lim_{x \to 0}\, _2F_1\left(1, 1, \frac{3}{2}-k, x\right) = 1$. Then, it remains to solve the following equation for $N$ 
\begin{equation}
\frac{(\sqrt{2m} \omega)^{2N}}{\alpha\omega \pi} \frac{\Gamma(N - 1/2)\Gamma(N + 3/2)}{(2N)!(2N + 1)!! (2N - 1)!!} = \epsilon.
\end{equation}
An asymptotic approximation follows by using Stirling approximation of the ratio of gamma functions and double factorials
\begin{equation}
\frac{\Gamma(N - 1/2)\Gamma(N + 3/2)}{(2N)!(2N + 1)!! (2N - 1)!!} \sim \frac{\sqrt{\pi}}{4} \left(\frac{e}{N}\right)^{2N} 2^{-4N}, \quad N \to \infty.
\end{equation}
obtaining a simplified equation
\begin{equation}
(\sqrt{2m} \omega)^{2N} \left(\frac{e}{N}\right)^{2N} 2^{-4N} = 4\sqrt{\pi}\alpha\omega\epsilon.
\end{equation}
The solution of the latter permits a closed-form in terms of principal branch of the Lambert $W$ function
\begin{equation}\label{N_expansion_xmu_acc}
N \approx - \frac{\log(A)}{W_0\left(-\frac{\log(A)}{2 e \sqrt{2m} \omega} \right)}, \quad A = 4\sqrt{\pi}\alpha\omega\epsilon.
\end{equation}

Table \ref{table_bound_remainder_xmu_b0_positive_large_N} shows the estimated number of terms of the accelerated convergent series \eqref{convergent_accelerated_series_xmu_b0_positive}, $N_{acc}$, and the actual number of terms $N^*$ to achieve machine-precision for small values of $\alpha\omega$ and $\delta$. The first and more notable observation is the reduction in the number of terms compared with convergent series \eqref{N_expansion_xmu_b0_positive}, especially for $\alpha \le 1$. The second observation is the accuracy of the estimate in $N_{acc}$ in \eqref{N_expansion_xmu_b0_positive}, which only seems to slightly underestimate $N$ for large $\alpha\omega$.

\begin{table}[H]
	\centering
	\scalebox{0.9}{
\begin{tabular}{ccccc|ccccc}
\hline
$x$ & $\alpha$ & $\mu$ & $\delta$ & $\alpha\omega$ & $N$ \eqref{N_expansion_xmu_b0_positive} & $N_{acc}$ \eqref{N_expansion_xmu_acc} & error & $N^*$ & error\\
\hline
	1 & 50 & 1/5 & 1/3 & 43.33 & 324 & 69 & $2.9\cdot 10^{-13}$ & 73 & $1.1\cdot 10^{-17}$\\
    2 & 5 & 1/5 & 1/10 & 9.01 & 10,242 & 25 & $4.6\cdot 10^{-21}$ & 22 & $1.1 \cdot 10^{-16}$\\
	1 & 1/10 & 1/5 & 1/100 & 0.08 & 179,715 & 5 & $1.3 \cdot 10^{-21}$ & 4 & $2.4 \cdot 10^{-17}$\\
	5 & 1 & 1/5 & 1/100 & 4.8 & 5,645,686 & 18 & $1.1 \cdot 10^{-22}$ & 15 & $1.5 \cdot 10^{-17}$\\
	20 & 1/100 & 1/5 & 1/100 & 0.198 & 84,914,922 & 6 & $1.1 \cdot 10^{-22}$ & 5 & $4.5 \cdot 10^{-19}$\\
	\hline
	\end{tabular}}
	\caption{Absolute error and bound \eqref{bound_remainder_xmu_b0_positive} estimating $N$ using \eqref{N_expansion_xmu_b0_positive} for the series expansion  \eqref{expansion_xmu_b0_positive} with machine-precision absolute error.}
	\label{table_bound_remainder_xmu_b0_positive_large_N}
\end{table}

\begin{remark}
A simpler bound for $R_N$, compared to \eqref{bound_remainder_xmu_b0_positive}, can be derived from the integral representation in \eqref{convergent_remainder_integral} as follows
\begin{align*}
R_N &= C \int_0^{\infty} \frac{\cos(\omega t)}{(t^2 + \alpha^2)^{N + 3/2}} \frac{1}{\left(2 - \frac{m}{t^2+ \alpha^2}\right)} \mathop{dt}\\
&\le \frac{C}{\left(2 - \frac{m}{\alpha^2}\right)} \int_0^{\infty} \frac{\cos(\omega t)}{(t^2 + \alpha^2)^{N + 3/2}} \mathop{dt}\\
&= \frac{1}{1 - \left(\frac{x-\mu}{\omega}\right)^2} T_N
\end{align*}

using the upper bound for $T_N$ in \eqref{bound_TN_xmu_b0_positive}, we obtain
\begin{equation}
R_N < \frac{1}{1 - \left(\frac{x-\mu}{\omega}\right)^2} \frac{1}{2\alpha\omega}\left(\frac{x-\mu}{\omega}\right)^{2N} \sqrt{\frac{\pi}{N + 1/2}}.
\end{equation}
\end{remark}

\subsubsection{Expansion $|x-\mu| \to \infty$}
To derive an asymptotic expansion for large $|x-\mu|$, we use the expansion derived in \eqref{phi_expansion_incgamma_t_small} as a starting point, taking $a = x-\mu$ and $b = 0$. Similar to the derivation of the expansion in \eqref{expansion_xmu_b0_alternating}, we interchange summation and integration, and the resulting integral is expressible in closed-form as a modified Bessel function, see Equation \eqref{bessel_integral}. Thus, for $x - \mu < 0$ we have the alternating asymptotic expansion
\begin{align}\label{asymptotic_expansion_xmu_b0}
F(x; \alpha, 0, \mu, \delta) &= \frac{\delta e^{\delta \alpha}}{2\pi} \sum_{k=0}^{\infty} \frac{(-1)^{k+1}}{k!} \frac{\Gamma(2k + 1)}{2^k (x-\mu)^{2k + 1}} \int_0^{\infty} t^{k-1} e^{-\frac{\omega^2}{2t} - \frac{\alpha^2}{2}t} \mathop{dt} \nonumber \\
&= -\frac{\delta e^{\delta \alpha}}{\pi (x-\mu)} \sum_{k=0}^{\infty}\frac{(-1)^k\Gamma(2k + 1)}{k!} \left(\frac{\omega}{2(x-\mu)^2\alpha}\right)^k K_k(\alpha \omega).
\end{align}
Note that the remainder is bounded in magnitude by the first neglected term. Moreover, the convergence of the expansion improves for large $\alpha$ and $\alpha / \omega > 1$. Finally, for the case $x - \mu > 0$ we use the reflection formula \eqref{cdf_mirror}.

\subsubsection{Uniform expansion $\alpha \to \infty$, $\alpha \sim \delta$ and $|x-\mu| \gg 0$}\label{uniform_expansion_alpha_large}
For large $\alpha$, we consider the uniform asymptotic expansion in terms of modified Bessel functions described in \cite{Temme1990c} and \cite[\S 27]{Temme2015}. We write the Laplace-type integral \eqref{integral_phi} in the standard form
\begin{equation*}
F_{\lambda}(z, r) = C\int_0^{\infty} t^{\lambda - 1} e^{-z\left(t + r^2/t\right)} f(t) \mathop{dt},
\end{equation*}
where $C$ is a normalizing constant, $\lambda=-1/2$, $z = \alpha^2/2$, $r=\delta/\alpha$ and $f(t) = \Phi((x-\mu)/\sqrt{t})$. The saddle point of $e^{-z\left(t + r^2/t\right)}$ occurs at $\pm r$, but only the positive saddle point $r$ lies inside the interval of integration. Thus, we expand $f(t)$ at the saddle point $r$
\begin{equation*}
f(t) = \sum_{k=0}^{\infty} c_k(r)(t-r)^k,
\end{equation*}
after interchanging the order of summation and integration, we obtain 
\begin{equation}
F_{\lambda}(z, r) \sim \frac{1}{z^{\lambda}} \sum_{k=0}^{\infty} \frac{c_k(r) Q_k(\zeta)}{z^k}, \quad z \to \infty,
\end{equation}
where
\begin{equation*}
Q_k(\zeta) = \zeta^{\lambda + k}\int_0^{\infty} t^{\lambda - 1}(t-1)^k e^{-\zeta(t + 1/t)} \mathop{dt}, \quad \zeta = rz.
\end{equation*}

For $f(t) = \Phi((x-\mu)/\sqrt{t})$ the coefficients at $t=r$ satisfy the recurrence in \eqref{phi_expansion_at_u} setting $a=x-\mu$ and $b=0$. In particular, the recurrence can be simplified as follows
\begin{equation}
c_0(r) = \Phi\left(\frac{x-\mu}{\sqrt{r}}\right), \quad c_1(r) = -\frac{(x-\mu)}{2 r^{3/2}} \phi\left(\frac{x-\mu}{\sqrt{r}}\right)
\end{equation}
and
\begin{equation}
c_k(r) = \frac{(k - 1) ((x-\mu)^2 - 4 r(k-2) - 3r) c_{k-1}(r) - (2(k-2)^2 + k-2) c_{k-2}(r)}{2r^2 (k-1) k}, \quad k\ge 2.
\end{equation}
The functions $Q_k(\zeta)$ can be expressed as a binomial sum of modified Bessel functions, and satisfy the recurrence relation \cite[\S 27.3.28]{Temme2015}
\begin{equation}
Q_{k+2}(\zeta) = \left(k + \frac{1}{2} -2\zeta\right) Q_{k+1}(\zeta) + \zeta\left(2k + \frac{1}{2}\right)Q_k(\zeta) + k\zeta^2 Q_{k-1}(\zeta), \quad k\ge 1,
\end{equation}
with initial values
\begin{equation}
Q_0(\zeta) = \frac{2}{\sqrt{\zeta}} K_{\frac{1}{2}}(2 \zeta), \quad Q_1(\zeta) = 0, \quad Q_2(\zeta) = 2 \zeta^{3/2} \left(K_{\frac{3}{2}}(2\zeta) - K_{\frac{1}{2}}(2 \zeta)\right),
\end{equation}
where the special case $K_{n+1/2}(z)$, $n \in \mathbb{N}$, is a terminating sum of elementary functions requiring $n$ terms, see \eqref{besselk_half}. In particular the cases $n=0$ and $n=1$ are
\begin{equation*}
K_{\frac{1}{2}}(z) = \sqrt{\frac{\pi}{2z}}e^{-z}, \quad K_{\frac{3}{2}}(z) = \sqrt{\frac{\pi}{2 z}}\frac{e^{-z} (z+1)}{z},
\end{equation*}
and subsequent terms can be computed via recursion.

Thus, rearranging terms we have
\begin{equation}\label{uniform_expansion_a_large}
F(x; \alpha, 0, \mu, \delta) = \frac{\alpha \delta e^{\delta \alpha}}{2 \sqrt{\pi}} \sum_{k=0}^{\infty} \frac{2^k c_k\left(\frac{\delta}{\alpha}\right) Q_k\left(\frac{\alpha \delta}{2}\right)}{\alpha^{2k}}, \quad \alpha \to \infty.
\end{equation}
The expansion \eqref{uniform_expansion_a_large} is a uniform expansion as $\alpha \to \infty$, uniformly with respect to $\delta / \alpha > 0$. Note that large values of $\delta$ improves the rate of convergence of the expansion, as observed taking well-know asymptotic estimates for large argument of the modified Bessel function. We remark that expansions \eqref{expansion_xmu_b0_alternating} and \eqref{expansion_xmu_b0_positive} are also adequate for large values of $\alpha$ and $\delta$, but unlike the present expansion, the number of terms increases significantly when $|x-\mu| \gg 0$.

\subsection{Special case $x = \mu$}
The second special case of interest, $x = \mu$, is arguably less common and has fewer applications, but it is nonetheless required to obtain a robust implementation. In particular, the attentive reader might have noticed that none of the series expansions already introduced are suitable for this specific case.

First consider the case $x = \mu$ and $\beta = 0$. Then, the distribution is symmetric and centered at $x = \mu$, and it follows that
\begin{equation}
F(\mu; \alpha, 0, \mu, \delta) = \frac{1}{2}.
\end{equation}

Secondly, for the case $\beta \neq 0$, the integral representation of this special case is given by simple substitution in \eqref{integral_k1}
\begin{equation}\label{integral_k1_x=mu}
F(\mu; \alpha, \beta, \mu, \delta) = \frac{\alpha \delta e^{\delta \gamma}}{\pi} \int_{-\infty}^{0} \frac{K_1\left(\alpha\sqrt{\delta^2 + t^2}\right)}{\sqrt{\delta^2 + t^2}} e^{\beta t} \mathop{dt}.
\end{equation}

Using the series expansion of the exponential function and interchanging the order of integration and summation in \eqref{integral_k1_x=mu} gives that
\begin{equation*}
F(\mu; \alpha, \beta, \mu, \delta) = 1 - \frac{\alpha \delta e^{\delta \gamma}}{\pi} \sum_{k=0}^{\infty}\frac{\beta^k}{k!}\int_{0}^{\infty} t^k \frac{K_1\left(\alpha\sqrt{\delta^2 + t^2}\right)}{\sqrt{\delta^2 + t^2}} \mathop{dt}.
\end{equation*}
The integral is expressible in closed form using \cite[\S 6.596]{gradshteyn2007}
\begin{equation*}
\int_0^{\infty} t^k \frac{K_1\left(\alpha\sqrt{\delta^2 + t^2}\right)}{\sqrt{\delta^2 + t^2}} \mathop{dt} = \frac{2^{\frac{k-1}{2}} \Gamma\left(\frac{k+1}{2}\right)}{\alpha^{\frac{k+1}{2}} \delta^{\frac{-k+1}{2}}}K_{\frac{k-1}{2}}(\alpha\delta),
\end{equation*}
and rearranging terms and using the connection formula $2^{k/2}  \Gamma\left(\frac{k+1}{2}\right)/ k! = \sqrt{\pi} 2^{-k/2} / \Gamma\left(\frac{k}{2} + 1\right)$ yields
\begin{align}
F(\mu; \alpha, \beta, \mu, \delta) &= 1 - \sqrt{\frac{\alpha \delta}{2\pi}}e^{\delta \gamma} \sum_{k=0}^{\infty}\frac{\beta^k}{2^{\frac{k}{2}}\Gamma\left(\frac{k}{2} + 1\right)} \left(\frac{\delta}{\alpha}\right)^{\frac{k}{2}} K_{\frac{k-1}{2}}(\alpha \delta)\\
&=\sqrt{\frac{\alpha \delta}{2\pi}}e^{\delta \gamma} \sum_{k=0}^{\infty}\frac{(-\beta)^k}{2^{\frac{k}{2}}\Gamma\left(\frac{k}{2} + 1\right)} \left(\frac{\delta}{\alpha}\right)^{\frac{k}{2}} K_{\frac{k-1}{2}}(\alpha \delta).
\end{align}
The resulting expansions are convergent and the latter series expansion is preferred for $\beta < 0$ to avoid cancellation errors. A more rapidly convergent expansion for $\delta < \gamma$ or large values of $\delta$ and $\gamma$ can be obtained using the integral \eqref{integral_phi} and expanding the term $\Phi(-\beta\sqrt{t})$. Replacing $\Phi(-\beta\sqrt{t})$ in the integral \eqref{integral_phi} with the expansion \eqref{phi_expansion_1} and interchanging the order of integration and summation, we obtain
\begin{equation}\label{expansion_x=mu_pre}
F(\mu; \alpha, \beta, \mu, \delta) = \frac{1}{2} + \frac{\delta e^{\delta \gamma}}{2\pi}\sum_{k=0}^{\infty}\frac{(-1)^k (-\beta)^{2k+1}}{2^k k! (2k+1)} \int_0^{\infty} t^{k - 1} e^{-\frac{\delta^2}{2t} - \frac{\gamma^2}{2}t} \mathop{dt},
\end{equation}
where we can express the integral in terms of the modified Bessel function \eqref{bessel_integral}. Plugging in \eqref{expansion_x=mu_pre}, now yields the alternating series
\begin{equation}\label{series_x=mu_1}
F(\mu; \alpha, \beta, \mu, \delta) = \frac{1}{2} + \frac{\delta e^{\delta \gamma}}{\pi} \sum_{k=0}^{\infty} \frac{(-1)^k (-\beta)^{2k+1}}{2^k k! (2k + 1)} \left(\frac{\delta}{\gamma}\right)^k K_k(\gamma \delta).
\end{equation}
Similarly, using \eqref{phi_expansion_2} yields
\begin{equation}\label{series_x=mu_2}
F(\mu; \alpha, \beta, \mu, \delta) = \frac{1}{2} + \frac{\delta e^{\delta \gamma}}{\pi} \sum_{k=0}^{\infty} \frac{(-\beta)^{2k+1}}{(2k + 1)!!} \left(\frac{\delta}{\alpha}\right)^k K_k(\alpha \delta).
\end{equation}
The latter expansion being more convenient since $\alpha \ge \gamma$.

Finally, to complement the series expansion, a special case of the asymptotic expansion defined in Equation \eqref{expansion_x_eq_mu_large_delta}, detailed in the next Section, can be employed for large values of $\delta$ and large $\alpha$, and its convergence improves as $\beta \sim \alpha$.


\subsection{General case}\label{section_general_case}
Comment: me make use of the expansion for the two special cases detailed in previous sections.

\subsubsection{Expansions $|x-\mu| \to 0$ in terms of modified Bessel functions}
We proceed to derive a series expansion for small $|x-\mu|$ following similar steps to those proposed for the special case $\beta = 0$. We use the expansion of $\Phi(x)$ in  \eqref{phi_expansion_2} to obtain
%\begin{equation*}
%F(x;\alpha, \beta, \mu, \delta) = \frac{\delta e^{\delta \gamma}}{\sqrt{2\pi}} \int_{0}^{\infty} \Phi\left(\frac{x - (\mu +\beta t)}{\sqrt{t}}\right) t^{-3/2} e^{-\frac{\delta^2}{2t} - \frac{\gamma^2}{2}t} \mathop{dt},
%\end{equation*}
\begin{equation}\label{general_series_xmu_zero_integral}
F(x;\alpha, \beta, \mu, \delta) = \frac{1}{2} + \frac{\delta e^{\delta \gamma}}{2\pi} \sum_{k=0}^{\infty} \frac{1}{(2k + 1)!!}I_k,
\end{equation}
\begin{equation}\label{general_xmu_zero_integral}
I_k = \int_0^{\infty} \left(\frac{x - (\mu +\beta t)}{\sqrt{t}}\right)^{2k+1} t^{-3/2} e^{-\frac{\delta^2}{2t} - \frac{\gamma^2}{2}t} e^{- \frac{(x-(\mu + \beta t)^2}{2t}} \mathop{dt}.
\end{equation}
The series expansion written in a more standard form is given by
\begin{equation}\label{general_series_xmu_zero_integral_2}
F(x;\alpha, \beta, \mu, \delta) = \frac{1}{2} + \frac{\delta e^{\delta \gamma + (x -\mu)\beta}}{2\pi}\sum_{k=0}^{\infty} \frac{(-\beta)^{2k+1}}{(2k + 1)!!}\int_0^{\infty} \left(t - \frac{x-\mu}{\beta}\right)^{2k+1} t^{-k-2} e^{-\frac{\omega^2}{2t} - \frac{\alpha^2}{2}t} \mathop{dt},
\end{equation}
where we denote $J_k$ the integral just introduced
\begin{equation}
J_k = \int_0^{\infty} \left(t - \frac{x-\mu}{\beta}\right)^{2k+1} t^{-k-2} e^{-\frac{\omega^2}{2t} - \frac{\alpha^2}{2}t} \mathop{dt}.
\end{equation}
The integral $J_k$ is expressible in terms of modified Bessel functions after applying the binomial expansion
\begin{equation}
J_k = 2 \left(\frac{-(x-\mu)}{\beta}\right)^{2k+1} \left(\frac{\alpha}{\omega}\right)^{k+1} \sum_{j=0}^{2k+1} (-1)^j \binom{2k+1}{j} \left(\frac{\omega \beta}{\alpha (x-\mu)}\right)^j K_{k + 1 - j}(\alpha \omega).
\end{equation}
Then, we have the series expansion
\begin{equation}\label{general_expansion_xmu_small_bessel}
F(x;\alpha, \beta, \mu, \delta) = \frac{1}{2} + \frac{(x-\mu)\alpha\delta e^{\delta \gamma + (x -\mu)\beta}}{\pi \omega}\sum_{k=0}^{\infty} \frac{A_k}{(2k+1)!!}\left(\frac{(x-\mu)^2\alpha}{\omega}\right)^k
\end{equation}
\begin{equation}
A_k = \sum_{j=0}^{2k+1} (-1)^j \binom{2k+1}{j} \left(\frac{\omega \beta}{\alpha (x-\mu)}\right)^j K_{k + 1 - j}(\alpha \omega)
\end{equation}
Observe that the convergence of the series improves for large values of $\alpha$ and $\delta$, hence it can be considered as a uniform asymptotic expansion with respect to these parameters. The first three coefficients $A_k$ are
\begin{align*}
A_0 &= -u K_0(z) + K_1(z)\\
A_1 &= 3u^2 K_0(z) - u(3 + u^2) K_1(z) + K_2(z)\\
A_2 &= -10u^3 K_0(z) + 5u^2(2 + u^2) K_1(z) - u(5 + u^4) K_2(z) + K_3(z)
\end{align*}
where, to compact notation, we use $u$ and $z$ defined as
\begin{equation}
u = \frac{\omega \beta}{\alpha (x-\mu)}, \quad z = \alpha \omega.
\end{equation}

Furthermore, the series expansion can be written as a truncated series with remainder. Using the representation in \eqref{general_series_xmu_zero_integral_2} we have a series in the form
\begin{equation}
\sum_{k=0}^{\infty} T_k = \sum_{k=0}^{N-1}T_k + \sum_{k=N}^{\infty} T_k, \quad T_k = \frac{(-\beta)^{2k+1}}{(2k+1)!!} I_k.
\end{equation}
The remainder, $R_N = \sum_{k=N}^{\infty} T_k$, integral representation is obtained as
\begin{align}\label{general_xmu_remainder_integral}
R_N &= \int_0^{\infty} e^{-\frac{\omega^2}{2t} - \frac{\alpha^2}{2}t} \left[ \sum_{k=N}^{\infty}\frac{(-\beta)^{2k+1}}{(2k+1)!!} \left(t - \frac{x-\mu}{\beta}\right)^{2k+1} t^{-k-2}\right] \mathop{dt}\\
&= \frac{(-1)^{2N + 1} 2^{N - 1/2} (2N + 1)}{(2N + 1)!!} e^{-\beta(x-\mu)} \int_0^{\infty} t^{-3/2} e^{-\frac{\delta^2}{2t} - \frac{\gamma^2}{2}t} \gamma\left(N + 1/2 , \frac{(\beta t - (x-\mu))^2}{2t}\right) \mathop{dt},
\end{align}
where $\gamma(a, z)$ is the lower incomplete gamma function. It remains to bound the remainder $R_N$. A simple but weak bound, since the dependence on $N$ disappears, is obtained by using the regularized incomplete gamma function $P(a,z) \Gamma(a) = \gamma(a, z)$ and the bound $P(a, z) \le 1$ for $z \ge 0$ (recall the asymptotic estimate $P(a,z) \to 1$ as $z \to \infty$). A sharper bound for $\gamma(a, z)$ derived from the asymptotic expansion for $a > z$ in \cite[\S 7.3]{Temme2015}, $\gamma(a, z) \sim \frac{z^a e^{-z}}{a}$ as $a \to \infty$, is given by
\begin{equation}\label{lower_incomplete_gamma_bound}
\gamma(a, z) \le \frac{z^a e^{-z}}{a - z - 1}, \quad a > z + 1, \quad z > 0.
\end{equation}
Since the use of this bound introduces a term involving $t$ in the denominator, complicating subsequent calculations, we use the asymptotic estimate instead. Thus, $|R_N|$ is approximated as
\begin{align}
|R_N| &\approx \frac{e^{-\beta(x-\mu)}}{(2N + 1)!!} I_N \label{remainder_approx1}\\
&\approx \frac{2 \beta^{2N + 1}}{(2N + 1)!!}\left(\frac{\omega}{\alpha}\right)^N K_N(\alpha \omega) \quad (|x-\mu| \to 0) \label{remainder_approx2},
\end{align}
and the latter approximation of $|R_N|$ can be simplified further by considering the asymptotic approximation in \eqref{besselk_order_to_inf}, which gives us
\begin{equation}
|R_N| \approx \sqrt{\frac{2\pi}{N}} \left(\frac{e\alpha^2}{2N}\right)^{-N} \frac{\beta^{2N + 1}}{(2N + 1)!!}.
\end{equation}
Observe that the approximation is only adequate for the case $\delta \to 0$ since its contribution is removed as a result of applying the specified asymptotic estimate. Table \ref{table_bound_remainder_xmu_general} compares the absolute value of the remainder in expression \eqref{general_xmu_remainder_integral}, $|R_N|$, with the upper bound using \eqref{lower_incomplete_gamma_bound} and the approximations in \eqref{remainder_approx1} and \eqref{remainder_approx2} for different parameters with small $|x-\mu|$. We can see that the bound is sharp for all cases considered, but requires the evaluation of an integral in terms of elementary functions. On the other hand, both approximations are close, only an order of magnitude off in most of the cases, and the approximation in terms of the modified Bessel function \eqref{remainder_approx2} might be seen as a suitable and fast approximation at least for small $\delta$.

\begin{table}[H]
	\centering
	\scalebox{0.9}{
\begin{tabular}{ccccc|ccccc}
\hline
$x$ & $\alpha$ & $\beta$ & $\mu$ & $\delta$ & $N$ & $R_N$ & Bound \eqref{lower_incomplete_gamma_bound} & \eqref{remainder_approx1} & \eqref{remainder_approx2}\\
\hline
	1/2 & 2 & 1 & 1/4 & 3 & 10 & $4.7\cdot 10^{-9}$ & $5.6\cdot 10^{-9}$ & $3.6\cdot 10^{-9}$ & $9.9\cdot 10^{-9}$\\
	1/3 & 5 & -1 & 1/4 & 1 & 50 & $2.5\cdot 10^{-72}$ & $2.6\cdot 10^{-72}$ & $2.4\cdot 10^{-73}$ & $2.8\cdot 10^{-73}$\\
	4 & 15 & -6 & 7/2 &  10 & 20 & $2.7\cdot 10^{-60}$ & $5.6\cdot 10^{-60}$ & $6.5\cdot 10^{-61}$ & $8.6\cdot 10^{-63}$\\
2/10 & 1 & 1/2 & 1/10 & 1/ 2 & 50 &  $1.1\cdot 10^{-33}$ & $1.1\cdot 10^{-33}$ & $7.9\cdot 10^{-34}$ & $9.8\cdot 10^{-34}$\\
	\hline
	\end{tabular}}
	\caption{Comparison of various approximations (\eqref{remainder_approx1} and \eqref{remainder_approx2}) and the upper bound \eqref{lower_incomplete_gamma_bound} for the estimation of the remainder \eqref{general_xmu_remainder_integral}.}
	\label{table_bound_remainder_xmu_general}
\end{table}

%Denote the integral $I_k$ as
%\begin{equation}
%I_k = \int_0^{\infty} (t- t_+)^{2k+1} t^{-k-2} e^{-z(t + \beta^2/t)} \mathop{dt},
%\end{equation}
%with $t_+ = \frac{x-\mu}{\beta}$, $z = \alpha^2 / 2$ and $\beta^2 = \omega^2 /  \alpha^2$. The integral $I_k$ can be expressed in terms of the modified Bessel expansion after applying the binomial expansion
%\begin{equation}
%I_k = 2\sum_{j=0}^{2k + 1}\binom{2k+1}{j} \left(-\frac{x-\mu}{\beta}\right)^{2k+1-j} \beta^{j-k-1} K_{k+1-j}(2z\beta).
%\end{equation}

\subsubsection{Expansion $|x-\mu| \to 0$ in terms of modified Bessel and incomplete gamma functions}
We present an alternative derivation of a series expansion for small $|x-\mu|$ where the series coefficients are easier to compute via recurrence relations. The starting point is the integral representation in \eqref{integral_phi} after expanding the exponential
%\begin{equation*}
%F(x;\alpha, \beta, \mu, \delta) = \frac{\delta e^{\delta \gamma}}{\sqrt{2\pi}} \int_{0}^{\infty} \Phi\left(\frac{x - (\mu +\beta t)}{\sqrt{t}}\right) t^{-3/2} e^{-\frac{\delta^2}{2t} - \frac{\gamma^2}{2}t} \mathop{dt},
%\end{equation*}
and replacing the term $\Phi\left(\frac{x - (\mu +\beta t)}{\sqrt{t}}\right)$ by the expansion in \eqref{phi_expansion_incgamma} in terms of upper incomplete gamma function $\Gamma(a, z)$. The resulting series is
\begin{equation}\label{general_xmu_incgamma_integral}
F(x;\alpha, \beta, \mu, \delta) = \frac{\delta e^{\delta \gamma}}{\sqrt{2\pi}} \sum_{k=0}^{\infty}\frac{2^{k/2}(x-\mu)^k}{k!}\int_0^{\infty}\Gamma\left(\frac{k+1}{2}, \frac{\beta^2}{2}t\right) t^{-3/2-k/2} e^{-\frac{\omega^2}{2t} - \frac{\gamma^2}{2}t} \mathop{dt}.
\end{equation}
Consider the ascending series of the incomplete gamma function given by \cite[\S 8.7]{NIST:DLMF}
\begin{equation}
\Gamma(a, z) = \Gamma(a) - \gamma(a, z) = \Gamma(a) - \sum_{j=0}^{\infty} \frac{(-1)^j z^{a+j}}{j! (a+ j)},
\end{equation}
and insert it into \eqref{general_xmu_incgamma_integral}, splitting the inner integral into two terms
\begin{align}
T_1 &= \Gamma\left(\frac{k+1}{2}\right)\int_0^{\infty}t^{-3/2-k/2} e^{-\frac{\omega^2}{2t} - \frac{\gamma^2}{2}t} \mathop{dt},\\
T_2 &= \sum_{j=0}^{\infty} \frac{(-1)^j \left(\frac{\beta^2}{2}\right)^{\frac{k+1}{2}+j}}{j! (\frac{k+1}{2}+ j)}\int_0^{\infty} t^{j-1} e^{-\frac{\omega^2}{2t} - \frac{\gamma^2}{2}t} \mathop{dt}.
\end{align}
Both integrals are expressible in terms of modified Bessel functions, respectively, resulting in the sums $S_1$ and $S_2$, such that $F(x;\alpha, \beta, \mu, \delta) = C (S_1 - S2)$. These series are defined as follows
\begin{align}
S_1 &= \sum_{k=0}^{\infty}\frac{2^{k/2}(x-\mu)^k}{k!} \Gamma\left(\frac{k+1}{2}\right)2 K_{\frac{k+1}{2}}(\omega \gamma) \left(\frac{\gamma}{\omega}\right)^{\frac{k+1}{2}},\\
S_2 &= \sum_{k=0}^{\infty}\frac{2^{k/2}(x-\mu)^k}{k!}\sum_{j=0}^{\infty}\frac{(-1)^j \left(\frac{\beta^2}{2}\right)^{\frac{k+1}{2}+j}}{j! (\frac{k+1}{2}+ j)} 2 K_j(\omega \gamma) \left(\frac{\omega}{\gamma}\right)^j.
\end{align}
Interchanging the order of summation in $S_2$, we observe that the sum in $k$ is convergent an expressible in terms of the lower incomplete gamma function $\gamma(a, x)$. Assuming $\beta > 0$ (otherwise, use \eqref{cdf_mirror}), we have
\begin{equation}
\sum_{k=0}^{\infty}\frac{2^{k/2}(x-\mu)^k}{k! (\frac{k+1}{2}+ j)} \left(\frac{\beta^2}{2}\right)^{\frac{k+1}{2}} = -\frac{\sqrt{2}}{(x-\mu)^{2j+1}\beta^{2j}} \gamma \left(2j + 1, -(x-\mu)\beta\right).
\end{equation}
Thus,
\begin{equation}
S_2 = -2\sqrt{2} \sum_{j=0}^{\infty} \frac{(-1)^j}{j!}\frac{\gamma \left(2j + 1, -(x-\mu)\beta\right)}{(x-\mu)^{2j+1}\beta^{2j}} \left(\frac{\beta^2}{2}\right)^j  K_j(\omega \gamma) \left(\frac{\omega}{\gamma}\right)^j.
\end{equation}
Rearranging terms, we obtain
\begin{align}\label{general_xmu_two_series}
F(x;\alpha, \beta, \mu, \delta) = \frac{\delta e^{\delta \gamma}}{\pi \sqrt{2}} \bigg[& \sum_{k=0}^{\infty}\frac{2^{k/2}(x-\mu)^k}{k!} \Gamma\left(\frac{k+1}{2}\right) K_{\frac{k+1}{2}}(\omega \gamma) \left(\frac{\gamma}{\omega}\right)^{\frac{k+1}{2}}\nonumber\\
& + \sqrt{2}\sum_{k=0}^{\infty} \frac{(-1)^k}{k!}\frac{\gamma \left(2k + 1, -(x-\mu)\beta\right)}{(x-\mu)^{2k+ 1}}  K_k(\omega \gamma) \left(\frac{\omega}{2\gamma}\right)^k \bigg]
\end{align}
The expansion converges rapidly for small $|x-\mu|$ and fixed values of the rest of parameters. Moreover, the convergence improves when $\gamma \sim \omega$, also valid of large values for these two parameters. The computation of the lower incomplete gamma functions in the second series $S_2$ can be performed using the recurrence relation
\begin{equation}
\gamma(a +1, z) = a \gamma(a, z) - z^a e^{-z}.
\end{equation}
However, one must take into account that forward recurrence for positive parameters $a$ and $z$ is unstable; we refer to \cite[\S 13]{Temme1996} for details on how to deal with unstable recurrence relations.

TODO: comment about the fact that caching modified Bessel functions is not necessary. No storage required. Consider the odd and even case for the recursion of gamma and modified Bessel. Numerical instability prevents its implementation in double-precision arithmetic. 

\subsubsection{Expansion $|x-\mu| \to 0$ in terms of Hermite polynomials}
Furthermore, we obtain an additional series expansion in terms of Hermite polynomials and the special case $x=\mu$, $F(\mu; \alpha, \beta, \mu, \delta)$. As in previous derivations, our starting point is the substitution of the term $\Phi\left(\frac{x - (\mu +\beta t)}{\sqrt{t}}\right)$ in \eqref{integral_phi}
by the Hermite-type expansion derived in \eqref{phi_expansion_a_small}. After inserting the expansion we have
\begin{equation}
F(x; \alpha, \beta, \mu, \delta) = F(\mu; \alpha, \beta, \mu, \delta) + \frac{\delta e^{\delta \gamma}}{2\pi} \sum_{k=0}^{\infty}\frac{(-1)^k (x-\mu)^{k+1}}{(k + 1)! 2^{k/2}}\int_0^{\infty} t^{-k/2 - 2} H_k\left(k, -\beta\sqrt{\frac{t}{2}}\right) e^{-\frac{\delta^2}{2t} - \frac{\alpha^2}{2}t} \mathop{dt}.
\end{equation}
Denote $I_k$ the integral in the series coefficients. The finite power series of $H_k(x)$ \cite[\S 18.5.13]{NIST:DLMF} allows the representation of $I_k$ as a finite series of modified Bessel functions. In this way, we obtain
\begin{align}
I_k  &= \int_0^{\infty} t^{-k/2 - 2} H_k\left(k, -\beta\sqrt{\frac{t}{2}}\right) e^{-\frac{\delta^2}{2t} - \frac{\alpha^2}{2}t} \mathop{dt}\\
&= 2k! \sum_{j=0}^{\lfloor k/2 \rfloor} \frac{(-1)^j}{j!(k - 2j)!} (-\beta\sqrt{2})^{k - 2j} \left(\frac{\alpha}{\delta}\right)^{j+1} K_{j+1}(\alpha \delta).
\end{align}
After rearranging terms, the series expansion reads as
\begin{equation}\label{general_xmu_small_hermite_series}
F(x; \alpha, \beta, \mu, \delta) = F(\mu; \alpha, \beta, \mu, \delta) + \frac{e^{\delta \gamma} (x-\mu) \alpha}{\pi} \sum_{k=0}^{\infty} \frac{(\beta(x-\mu))^k}{k+1}A_k,
\end{equation}
\begin{equation}
A_k = \sum_{j=0}^{\lfloor k/2 \rfloor} \frac{(-1)^j}{j!(k - 2j)!} \left(\frac{\alpha}{2\delta \beta^2}\right)^j K_{j+1}(\alpha \delta).
\end{equation}

Table \ref{table_xmu_general_n_terms} compares the number of terms of the three presented series expansion for the case $|x-\mu| \to 0$ for various sets of parameters to achieve a target accuracy of machine precision. As a first observation, we note that the Hermite-type expansion \eqref{general_xmu_small_hermite_series} appears to be the most efficient when $|x-\mu| \ll 1$. Also, in this regime, both series expansions \eqref{general_xmu_two_series} and \eqref{general_expansion_xmu_small_bessel} require a similar number of terms $N$. On the other hand, in the region $|x-\mu| \ge 1$, the expansion \eqref{general_expansion_xmu_small_bessel} becomes the most efficient in the cases considered.

\begin{table}[H]
	\centering
	\scalebox{0.9}{
\begin{tabular}{ccccc|ccc}
\hline
$x$ & $\alpha$ & $\beta$ & $\mu$ & $\delta$ & \eqref{general_expansion_xmu_small_bessel} & \eqref{general_xmu_two_series} & \eqref{general_xmu_small_hermite_series}\\
\hline
	1/2 & 2 & 1 & 1/4 & 3 & 27 & 32 & 15\\
	1/3 & 5 & -1 & 1/4 & 1 & 12 & 17 & 14\\
	4 & 15 & -6 & 7/2 &  10 & 63 & 67 & 17\\
	2/10 & 1 & 1/2 & 1/10 & 1/2 & 22 & 25 & 19\\
	2 & 3 & 2 & 1 & 2 & 42 & 152 & 52\\
	3 & 5 & 1/2 & 1 & 4 & 29 & 63 & 66\\
	\hline
	\end{tabular}}
	\caption{Comparison on the number of terms to achieve machine precision with the three series expansions for $|x-\mu| \to 0$.}
	\label{table_xmu_general_n_terms}
\end{table}

\subsubsection{Expansion $\beta \to 0$} 
For the case $\beta \to 0$, we follow closely the derivation of the Hermite-type expansion for $|x-\mu| \to 0$ in \eqref{general_xmu_small_hermite_series}, hence some steps are omitted. In this case, the expansion involves the special case $\beta = 0$ studied in detail in Section \ref{section_special_case_beta_0}. Replacing the Hermite-type expansion defined in \eqref{phi_expansion_b_small} in integral \eqref{integral_phi}, we obtain
\begin{equation}
F(x; \alpha, \beta, \mu, \delta) = F(x; \gamma, 0, \mu, \delta) + \frac{\delta e^{\delta \gamma}}{2\pi} \sum_{k=0}^{\infty} \frac{(-1)^k (-\beta)^{k+1}}{(k+1)! 2^{k/2}} \int_0^{\infty} H_k\left(\frac{x-\mu}{\sqrt{2t}}\right) t^{k/2 - 1} e^{-\frac{\omega^2}{2t} - \frac{\gamma^2}{2}t} \mathop{dt}.
\end{equation}
We may apply some algebraic manipulations to obtain an expansion in the same form as \eqref{general_xmu_small_hermite_series}, obtaining
\begin{equation}\label{general_beta_small_hermite_series}
F(x; \alpha, \beta, \mu, \delta) = F(x; \gamma, 0, \mu, \delta) -\frac{\beta \delta e^{\delta \gamma}}{\pi}\sum_{k=0}^{\infty} \frac{(\beta(x-\mu))^k}{k+1}B_k,
\end{equation}
\begin{equation}
B_k = \sum_{j=0}^{\lfloor k/2 \rfloor} \frac{(-1)^j}{j!(k - 2j)!} \left(\frac{\omega}{2\gamma (x-\mu)^2}\right)^j K_{j}(\gamma \omega),
\end{equation}
where we can observe the similarity of the terms in both Hermite-type expansions.

\subsubsection{Expansion $\delta \to \infty$}
Starting from the integral representation in \eqref{integral_phi} and replacing the $\Phi\left(\frac{x-(\mu + \beta t)}{\sqrt{t}}\right)$ by the asymptotic expansion for $t\to \infty$ in \eqref{phi_expansion_at_inf} in terms of the incomplete gamma function. Taking $a = x -\mu$ and $b = -\beta$, we obtain
\begin{equation}
F(x; \alpha, \beta, \mu, \delta) = \frac{\delta e^{\delta \gamma}}{2\pi} \sum_{k=0}^{\infty}\frac{(-1)^{k+1}}{2^k k!} \frac{\Gamma(2k+1, -(x-\mu)\beta)}{(-\beta)^{2k+1}} \int_0^{\infty} t^{-k-2} e^{-\frac{\delta^2}{2t} - \frac{\gamma^2 + \beta^2}{2}t} \mathop{dt}.
\end{equation}
The integral is expressible in terms of modified Bessel function
\begin{equation}
\int_0^{\infty} t^{-k-2} e^{-\frac{\delta^2}{2t} - \frac{\gamma^2 + \beta^2}{2}t} \mathop{dt} = 2 \left(\frac{\alpha}{\delta}\right)^{k + 1} K_{k+1}(\alpha \delta),
\end{equation}
where we use the fact that $\gamma^2+ \beta^2 = \alpha^2$. After rearranging terms, we have for $\beta > 0$
\begin{align}\label{general_asymptotic_delta}
F(x; \alpha, \beta, \mu, \delta) &= \frac{\alpha e^{\delta \gamma}}{\pi \beta}\sum_{k=0}^{\infty} \frac{(-1)^k}{k!} \Gamma(2k + 1, -(x-\mu)\beta)\left(\frac{\alpha}{2\beta^2 \delta}\right)^k K_{k+1}(\alpha \delta)\\
 &=\frac{\alpha e^{\delta \gamma}}{\pi \beta}\sum_{k=0}^{\infty} Q(2k + 1, -(x-\mu)\beta)\frac{\Gamma(2k+1)}{\Gamma(k+1)}\left(-\frac{\alpha}{2\beta^2 \delta}\right)^k K_{k+1}(\alpha \delta)\\
 &=\frac{\alpha e^{\delta \gamma}}{\pi^{3/2} \beta}\sum_{k=0}^{\infty} Q(2k + 1, -(x-\mu)\beta) \Gamma(k + 1/2)\left(-\frac{2\alpha}{\beta^2 \delta}\right)^k K_{k+1}(\alpha \delta),
\end{align}
and $1 + F(x; \alpha, \beta, \mu, \delta)$ for $\beta < 0$. We can rewrite the asymptotic series in terms of the regularized incomplete gamma function $Q(a, x)$, see appendix \ref{appendix_incomplete_gamma}, to avoid ratios with large numerator and denominator. In addition, the evaluation of the upper incomplete gamma function , $\Gamma(a, z)$, and its regularized version via recurrence is numerically stable for positive parameters $a$ and $z$,
\begin{equation}
\Gamma(a + 1, z) = a \Gamma(a, z) + z^a e^{-z}.
\end{equation}

Furthermore, the special case $x=\mu$ simplifies the asymptotic expansion considerably since $\Gamma(a, 0) = 1$ for $a > 0$, obtaining for $\beta > 0$
\begin{equation}\label{expansion_x_eq_mu_large_delta}
F(\mu; \alpha, \beta, \mu, \delta) = \frac{\alpha e^{\delta \gamma}}{\pi^{3/2} \beta}\sum_{k=0}^{\infty}\Gamma(k + 1/2)\left(-\frac{2\alpha}{\beta^2 \delta}\right)^k K_{k+1}(\alpha \delta)
\end{equation}

\subsubsection{Expansion $|x-\mu| \to \infty$}
%In a similar manner, an asymptotic expansion for large $|x-\mu|$ can be derived replacing $\Phi(\cdot)$ term in the integral \eqref{integral_phi} by its expansion in terms of modified Bessel functions in \eqref{phi_expansion_besselk}. Then,
%\begin{equation}
%F(x; \alpha, \beta, \mu, \delta) = 1 + \delta e^{\delta \gamma} \sqrt{\frac{b}{2a\pi^3}}\sum_{k=0}^{\infty} (-1)^{k+1} \left(\frac{b}{a}\right)^k K_{k + \frac{1}{2}}(ab)\int_0^{\infty}t^{k-1} e^{-\frac{\delta^2 + a^2}{2t} -\frac{\gamma^2 + b^2}{2}t} \mathop{dt}.
%\end{equation}
%After setting $a = x-\mu$ and $b=-\beta$, we express the integral in the series in terms of the modified Bessel function,
%\begin{equation}
%\int_0^{\infty}t^{k-1} e^{-\frac{\delta^2 + a^2}{2t} -\frac{\gamma^2 + b^2}{2}t} \mathop{dt} = 2 K_k(\omega \alpha) \left(\frac{\omega}{\alpha}\right)^k.
%\end{equation}
%It simply remains to rearrange terms to obtain an asymptotic series involving the product of two Bessel functions,
%\begin{equation}
%F(x; \alpha, \beta, \mu, \delta) = 1 + \delta e^{\delta \gamma} \sqrt{\frac{2\beta}{(\mu-x)\pi^3}}\sum_{k=0}^{\infty} (-1)^{k+1} \left(\frac{\beta \omega}{\alpha(\mu-x)}\right)^k K_{k + \frac{1}{2}}((\mu-x)\beta) K_k(\omega \alpha),
%\end{equation}
%where we assumed $\text{sign}((\mu-x)\beta) = 1$.

In a similar manner, using instead the expansion in \eqref{phi_expansion_incgamma_t_small}, we obtain for $x-\mu < 0$ the asymptotic expansion
\begin{equation}\label{general_asymptotic_xmu}
F(x; \alpha, \beta, \mu, \delta) = -\frac{\delta e^{\delta\gamma}}{\pi (x-\mu)}\sum_{k=0}^{\infty}\frac{(-1)^k}{k!}\Gamma(2k + 1, -(x-\mu)\beta) \left(\frac{\omega}{2\gamma (x-\mu)^2}\right) K_k(\gamma \omega),
\end{equation}
and use $1 + F(x; \alpha, \beta, \mu, \delta)$ for $x-\mu > 0$. The same comments about the computation of the series using the recurrence of the upper incomplete gamma and modified Bessel function apply.

\subsubsection{Uniform asymptotic $\gamma \to \infty, \gamma \sim \delta$ and $|x-\mu| \gg 0$}
For large $\gamma$, we employ the uniform asymptotic described in Section \ref{uniform_expansion_alpha_large}. The only difference is the calculation of the coefficients $c_k(r)$ using the recurrence in \eqref{phi_expansion_at_u} with $a = x-\mu$ and $b = -\beta$. The resulting uniform asymptotic expansion reads
\begin{equation}
F(x; \alpha, \beta, \mu, \delta) = \frac{\gamma \delta e^{\delta \gamma}}{2\sqrt{\pi}} \sum_{k=0}^{\infty} \frac{2^k c_k\left(\frac{\delta}{\gamma}\right) Q_k\left(\frac{\gamma\delta}{2}\right)}{\gamma^{2k}}, \quad \gamma \to \infty.
\end{equation}


TODO: expansion for $\beta \to 0$ is also asymptotic for $\gamma \to \inf$, but requires small $|x-\mu|$.

\subsection{Numerical integration}\label{section_numerical_integration}
\subsubsection{Integrand in terms of the error function}

For cases do not covered by the described expansions, we need to resort to numerical integration. First, we focus on the Laplace-type integral \eqref{integral_phi}, whose integrand involves the complementary error function, since its evaluation is faster than the Bessel integral in \eqref{integral_k1}.

As a preliminary step, we truncate the improper integral \eqref{integral_phi} at some point $N > 0$, such that
\begin{equation}\label{truncated_integral}
I_N = \int_0^N \Phi\left(\frac{x - (\mu +\beta t)}{\sqrt{t}}\right) t^{-3/2} e^{-\frac{\delta^2}{2t} - \frac{\gamma^2}{2}t} \mathop{dt} + \int_N^{\infty} \Phi\left(\frac{x - (\mu +\beta t)}{\sqrt{t}}\right) t^{-3/2} e^{-\frac{\delta^2}{2t} - \frac{\gamma^2}{2}t} \mathop{dt},
\end{equation}
and $F(x; \alpha, \beta, \mu, \delta) = C I_N$, where $C = \frac{\delta e^{\delta \gamma}}{\sqrt{2\pi}}$. The truncation error can be bounded by
\begin{equation}
\int_N^{\infty} \Phi\left(\frac{x - (\mu +\beta t)}{\sqrt{t}}\right) t^{-3/2} e^{-\frac{\delta^2}{2t} - \frac{\gamma^2}{2}t} \mathop{dt} \le \frac{e^{-\frac{\delta^2}{2N}}}{N^{3/2}}\int_N^{\infty} e^{- \frac{\gamma^2}{2}t} \mathop{dt} \le \frac{2 e^{-\frac{\delta^2}{2N} - \frac{\gamma^2}{2}N}}{N^{3/2} \gamma^2}.
\end{equation}
We can select $N$ for a desired absolute tolerance $\epsilon$ solving numerically the equation
\begin{equation}
\frac{2 e^{-\frac{\delta^2}{2N} - \frac{\gamma^2}{2}N}}{N^{3/2} \gamma^2} = \frac{\epsilon}{C}.
\end{equation}
Moreover, a slightly lesser sharper bound allows a closed-form solution of the above equation in terms of the principal branch of the Lambert $W$ function, $W_0(z)$
\begin{equation}\label{N_equation}
\frac{2 e^{- \frac{\gamma^2}{2}N}}{N^{3/2} \gamma^2} = \frac{\epsilon}{C} \longrightarrow N = \frac{3}{\gamma^2}W_0\left(\frac{\gamma^2}{3u}\right), \quad u = \left(\frac{\gamma^2 \epsilon}{2 C}\right)^{2/3}.
\end{equation}
To reduce the cost of evaluating $N$, we can accurately approximate $W_0(z)$ for $z > 1$ using the upper bound derived in \cite{Hoorfar2008}
\begin{equation}\label{lambertW0_upper_bound}
W_0(z) \le \log(z)^{\tfrac{\log(z)}{1 + \log(z)}},
\end{equation}
implying that we can safely use this approximation when the following inequality is satisfied (which should occur for any reasonable set of parameters)
\begin{equation}
\delta \gamma e^{\delta\gamma} > \sqrt{\frac{27 \pi}{2}} \epsilon.
\end{equation}
Note that, from an implementation perspective, the use of the upper bound  \eqref{lambertW0_upper_bound} to estimate $N$ avoids overflow/underflow issues for large parameters by directly using logarithmic properties. 
To accurately estimate $N$ to achieve a relative tolerance, we need an estimate of the order of magnitude of $I$. The integrand can be written as $e^{g(t)}$, where
\begin{equation}
g(t) = -\frac{\delta^2}{2t} - \frac{\gamma^2}{2}t - \frac{3}{2}\log(t) + \log\left(\Phi\left(\frac{x - (\mu +\beta t)}{\sqrt{t}}\right)\right),
\end{equation}
and
\begin{equation}\label{saddle_point_equation}
g'(t) = \frac{\delta^2}{2t^2} -\frac{\gamma^2}{2} -\frac{3}{2t} -\frac{1}{2}\left(\frac{x-\mu}{t^{3/2}} + \frac{\beta}{\sqrt{t}} \right)\frac{\phi\left(\frac{x - (\mu +\beta t)}{\sqrt{t}}\right)}{\Phi\left(\frac{x - (\mu +\beta t)}{\sqrt{t}}\right)}.
\end{equation}
The saddle point $t_0$ and maximum contribution $e^{g(t_0)}$ of the integrand is obtained as the solution of the equation $g'(t) = 0$. Thus, $N$ for relative tolerance can be estimated after replacing $\epsilon$ with $\epsilon e^{g(t_0)}$ in \eqref{N_equation}. For the case where $\gamma$ and $\delta$ are both large and $\beta$ and $x-\mu$ are fixed, the last term in $g'(t)$ can be neglected, obtaining the quadratic equation
\begin{equation}\label{saddle_point_1}
g'(t) \approx \frac{\delta^2}{2t^2} -\frac{\gamma^2}{2} -\frac{3}{2t}, \quad t_0 = \frac{-\frac{3}{2} + \sqrt{\frac{9}{4} + (\gamma \delta)^2}}{\gamma^2},
\end{equation}
taking the positive internal saddle point $t_0$. The case where $\gamma$ and $\delta$ are small requires further analysis. If $x-\mu > 0$, $t_0$ in \eqref{saddle_point_1} is still valid. Contrarily, if $x -\mu < 0$, the ratio of the cumulative distribution function and the density function can be approximated via
\begin{equation*}
\frac{\phi\left(\frac{x - (\mu+ \beta t)}{\sqrt{t}}\right)}{\Phi\left(\frac{x - (\mu + \beta t)}{\sqrt{t}}\right)} \approx -\frac{x - (\mu + \beta t)}{\sqrt{t}},
\end{equation*}
then, replacing in \eqref{saddle_point_equation}, we have another quadratic equation
\begin{equation}\label{saddle_point_2}
g'(t) \approx \frac{\delta^2 + (x-\mu)^2}{2t^2} -\frac{\alpha^2}{2} -\frac{3}{2t}, \quad t_0 = \frac{-\frac{3}{2} + \sqrt{\frac{9}{4} + \alpha^2 \left((x-\mu)^2 + \delta^2\right)}}{\alpha^2}.
\end{equation}
%If $\beta < 0$, a better approximation is
%\begin{equation*}
%g'(t) \approx \frac{\delta^2}{2t^2} -\frac{\gamma^2}{2} -\frac{3}{2t} + \frac{(x-\mu)^2}{2t^2} + \frac{\beta(x-\mu)}{2t}, \quad t_0 = \frac{h + \sqrt{h^2 + \gamma^2 \left((x-\mu)^2 + \delta^2\right)}}{\gamma^2}, \quad h = \frac{\beta (x-\mu) - 3}{2}.
%\end{equation*}
The saddle point estimates $t_0$ computed by \eqref{saddle_point_1} or \eqref{saddle_point_2} is used as a starting point for the root-finding method. In particular, we find that the Newton's method setting an absolute error $10^{-4}$ only requires a few iterations (typically less than 5) to refine the initial estimate. After estimating $N$ using the estimated magnitude with the saddle point $t_0$, $\epsilon e^{g(t_0)}$, the truncated integral \eqref{truncated_integral} can be computed using standard numerical integration methods such as double exponential (tanh-sinh) quadrature or Gaussian quadrature (Gauss-Legendre). Technical details are discussed in Section \ref{algorithmic_numerical_integration}.


\subsubsection{Integrand in terms of elementary functions}
Most of the integral representations presented in Section \ref{properties_cdf} involve special functions in their integrands (e.g., $K_1(x)$ or $\erfc(x)$), which necessarily increases the computation cost of their evaluation. Therefore, for computational efficiency, it is generally preferred to evaluate integrals representable in terms of elementary functions. A suitable integral representation satisfying this requirement was given in \eqref{integral_sine_transform}. As previously described, the integral \eqref{integral_sine_transform} can be approximated by the truncated integral 
\begin{equation}\label{truncated_integral_sine_transform}
I_N = \int_0^N \frac{t e^{-(x-\mu)\left(\sqrt{t^2 + \alpha^2} - \beta\right)}}{\sqrt{t^2 + \alpha^2}\left(\sqrt{t^2 + \alpha^2} - \beta\right)}\sin(\delta t)\mathop{dt} + \int_N^{\infty} \frac{t e^{-(x-\mu)\left(\sqrt{t^2 + \alpha^2} - \beta\right)}}{\sqrt{t^2 + \alpha^2}\left(\sqrt{t^2 + \alpha^2} - \beta\right)}\sin(\delta t)\mathop{dt},
\end{equation}
and $F(x; \alpha, \beta, \mu, \delta) = 1 - C I_N$, where $C = \frac{e^{\delta \gamma}}{\pi}$. Consider the tail given by
\begin{equation}
T_N = \int_N^{\infty} \frac{t e^{-(x-\mu)\left(\sqrt{t^2 + \alpha^2} - \beta\right)}}{\sqrt{t^2 + \alpha^2}\left(\sqrt{t^2 + \alpha^2} - \beta\right)}\sin(\delta t)\mathop{dt}.
\end{equation}
An upper bound for the tail holds:
\begin{align*}
|T_N| &\le \int_N^{\infty} \frac{t e^{-(x-\mu)\left(\sqrt{t^2 + \alpha^2} - \beta\right)}}{\sqrt{t^2 + \alpha^2}\left(\sqrt{t^2 + \alpha^2} - \beta\right)}\mathop{dt}\\
&\le \frac{e^{(x-\mu)\beta}}{\sqrt{N^2 + \alpha^2} - \beta}\int_N^{\infty} e^{-(x-\mu)\sqrt{t^2 + \alpha^2}} \mathop{dt}\\
&\le \frac{e^{(x-\mu)\beta}}{\sqrt{N^2 + \alpha^2} - \beta} \sqrt{N^2 + \alpha^2} K_1((x-\mu)\sqrt{N^2 + \alpha^2}),
\end{align*}
where we use the fact that $|\sin(\delta t)| \le 1$, and a bound for the latter integral expressible in closed form using \cite[\S 3.461]{gradshteyn2007}
\begin{equation*}
\int_N^{\infty} e^{-(x-\mu)\sqrt{t^2 + \alpha^2}} \mathop{dt} \le \int_0^{\infty} e^{-(x-\mu)\sqrt{t^2 + N^2 + \alpha^2}} \mathop{dt} = \sqrt{N^2 + \alpha^2} K_1((x-\mu)\sqrt{N^2 + \alpha^2}).
\end{equation*}

\begin{remark}The previous bound involving the modified Bessel function $K_1(z)$ can be simplified at the expense of obtaining a slightly less sharper bound. Using the monotonicity properties of $K_{\nu}(z)$ for $z > 0$, we have that $K_1(z) < K_{3/2}(z)$, with $K_{3/2}(z)$ being expressible via elementary functions
\begin{equation*}
\quad K_{\frac{3}{2}}(z) = \sqrt{\frac{\pi}{2}}\frac{e^{-z} (z+1)}{z^{3/2}}.
\end{equation*}
Hence, one can obtain
\begin{equation}
|T_N| \le \sqrt{\frac{\pi}{2}} \frac{\sqrt{N^2 + \alpha^2}(\sqrt{N^2 + \alpha^2} + 1)}{(\sqrt{N^2 + \alpha^2} - \beta)\left(N^2 + \alpha^2\right)^{3/4}} e^{-(x-\mu)\left(\sqrt{N^2 + \alpha^2} - \beta\right)}.
\end{equation}
\end{remark}
Although the derived bounds are accurate, the inversion to obtain $N$ is far from trivial. In contrast, a practical bound, improving as $N$ increases $(N \gg \alpha > |\beta|)$ is given by
\begin{equation}
|T_N| \le \frac{e^{-(x-\mu)(N - \beta)}}{N - \beta} \approx \frac{e^{-(x-\mu)(N-\beta)}}{N},
\end{equation}
where $\beta$ is neglected from the denominator. To select $N$, we take the simplified bound and equate to a prescribed accuracy $\epsilon$. The solution admits a closed-form in terms of $W_0(z)$
\begin{equation}
\frac{e^{-(x-\mu)(N-\beta)}}{N} = \frac{\epsilon}{C} \longrightarrow N = \frac{1}{x-\mu}W_0\left(\frac{C e^{(x-\mu)\beta}}{\epsilon}\right).
\end{equation}

It is important to note that the integrand in \eqref{truncated_integral_sine_transform} becomes highly oscillatory for large $\delta$. Therefore, the direct computation in the presence of high oscillations leads to catastrophic cancellation, requiring a prohibited number of quadrature points for convergence. The literature on numerical quadrature methods for highly oscillatory integrals is extensive and we do not aim to cover it in detail. However, as an example, we show the application of the steepest descent method and its adequacy in this case. We transform the integral with sine kernel into the complex form
\begin{equation}\label{sine_transform_complex_integral}
F(x; \alpha, \beta, \mu, \delta) = 1 - \frac{e^{\delta \gamma}}{\pi}\Im\left(\int_0^{\infty} \frac{t e^{-(x-\mu)\left(\sqrt{t^2 + \alpha^2} - \beta\right) + \delta t i}}{\sqrt{t^2 + \alpha^2}\left(\sqrt{t^2 + \alpha^2} - \beta\right)}\mathop{dt}\right), \quad x-\mu > 0,
\end{equation}
and apply the change of variable $t = i q / \delta$ which yields
\begin{equation}
F(x; \alpha, \beta, \mu, \delta) = 1 + \frac{e^{\delta \gamma + (x-\mu) \beta}}{\pi \delta^2} \Im\left(\int_{0}^{\infty} \frac{q e^{-(x-\mu)\sqrt{\alpha^2 - q^2/\delta^2} - q}}{\sqrt{\alpha^2 - q^2/\delta^2}\left(\sqrt{\alpha^2 - q^2/\delta^2} -\beta\right)} \mathop{dq}\right).
\end{equation}
The integrand has two poles located at $q = \delta \alpha$ and $q = \delta\sqrt{\alpha^2 - \beta^2} = \delta \gamma$, but observe that the imaginary part of the integral only differs from zero when $q > \delta \alpha$. Consequently, the interval of integration can be shifted to $(\delta \alpha, \infty)$ removing the pole ($\delta \alpha \ge \delta \gamma$) which gives
\begin{equation}\label{sine_transform_complex_integral_non_oscillatory}
F(x; \alpha, \beta, \mu, \delta) = 1 + \frac{e^{\delta \gamma + (x-\mu) \beta}}{\pi \delta^2} \Im\left(\int_{\delta\alpha}^{\infty} \frac{q e^{-(x-\mu)i\sqrt{q^2/\delta^2 - \alpha^2} - q}}{i\sqrt{q^2/\delta^2 - \alpha^2}\left(i\sqrt{q^2/\delta^2 - \alpha^2} -\beta\right)} \mathop{dq}\right),
\end{equation}
where the resulting integrand prevents the evaluation of complex square roots. The previously mentioned numerical integration methods are applicable to the non-oscillatory integral \eqref{sine_transform_complex_integral_non_oscillatory}, but also Gauss-Laguerre quadrature with weight function $q^r e^{-q}$, $r \in \{0, 1\}$.

%A similar expansion can be obtained from the integral representation \eqref{integral_k0}, expanding $e^{\sqrt{2}(x-\mu)t}$
%\begin{equation*}
%e^{\sqrt{2}(x-\mu)t} = \sum_{k=0}^{\infty} \frac{2^{k/2} (x-\mu)^k}{k!} t^k
%\end{equation*}
%
%\begin{equation*}
%F(x; \alpha, 0, \mu, \delta) = \frac{\sqrt{2}\delta e^{\delta \gamma}}{\pi} \sum_{k=0}^{\infty} \frac{2^{k/2} (x-\mu)^k}{k!} \int_{0}^{\infty} t^k K_0\left(\sqrt{2\left( (x-\mu)^2 + \delta^2\right)} \sqrt{\frac{\gamma^2}{2} + t^2}\right) \mathop{dt}
%\end{equation*}
%Use closed-form in terms of the modified Bessel function
%\begin{equation}
%F(x; \alpha, 0, \mu, \delta) = \frac{\delta e^{\delta \gamma}}{2\pi} \sum_{k=0}^{\infty} \frac{(x-\mu)^k}{2^{k/2} \Gamma\left(\frac{k}{2} + 1\right)}\left(\frac{\alpha}{\omega}\right)^{\frac{k+1}{2}}K_{\frac{k+1}{2}}(\omega \alpha), \quad \omega = \sqrt{\delta^2 + (x-\mu)^2}.
%\end{equation}


%\subsection{Inversion methods}
%Ideas:
%\begin{itemize}
%\item Central region
%\begin{enumerate}
%\item The moment generating function is simple. The computation of its central moments is easy.
%\item Use multiple central moments to estimate the quantile using a Cornish-Fisher expansion.
%\end{enumerate}
%\item Tails (asymptotic methods) \cite[\S 42]{Temme2015}
%\begin{enumerate}
%\item Direct application using the standard form integral representation \eqref{integral_k1}.
%\end{enumerate}
%\item Root-finding: Halley's or Schwarzian-Newton method.
%\end{itemize}

\section{Algorithmic details and implementation}
\subsection{Evaluation of Bessel-type expansions}
Recurrence relation in terms of ration of modified Bessel functions. More numerically stable.
\label{subsection_evaluation_bessel_expansions}

\subsubsection{Handling large parameters}
Exponent overflow issues in $\exp(\alpha \delta)$. Logarithmic transformation. Use scaled Bessel function.

\subsubsection{Partial sums recurrence}
As an example, series \eqref{expansion_xmu_b0_positive}. It is worth noticing that performing a naive computation of the terms $T_k$ in double-precision arithmetic for large $N$ poses underflow and overflow problems since the numerator (denominator) rapidly goes to infinity (zero) as $N$ increases. In Section \ref{subsection_evaluation_bessel_expansions}, we discuss alternative summation methods to avoid cancellation issues and precision loss for large $N$.

\begin{equation}
F(x;\alpha, 0, \mu, \delta) = \frac{1}{2} + \frac{\delta e^{\delta \alpha}}{\pi}\frac{(x-\mu) \alpha}{\omega}S_K,
\end{equation}
where $S_K$ is the $k$-th partial sum. The first partial sums are
\begin{equation}
S_0 = 0, \quad S_1 = K_1(\alpha \omega), \quad S_2 = S_1 + \frac{K_2(\alpha \omega)z}{3},
\end{equation}
and for $k \ge 0$, the partial sums satisfy the recursion relation
\begin{equation}
S_{k+3} = \frac{-\alpha\omega z^2 S_k + z \left(-2 (2+k) (3 + 2k) + \alpha\omega\right) S_{k+1} + (3 + 2k) \left((5 + 2k) \alpha\omega + 2(2+k)z\right) S_{k+2}}{(3 + 2k) (5 + 2k) \alpha \omega},
\end{equation}
where
\begin{equation}
z = \frac{(x-\mu)^2 \alpha}{\omega}.
\end{equation}
Stopping criterion is
\begin{equation}
\left|1 - \frac{S_{K}}{S_{K-1}} \right| < \epsilon.
\end{equation}

\begin{itemize}
\item Computation of 2F1, use partial sums recursion with Mathematica.
\end{itemize}

\subsubsection{Comparison Bessel $K_0(x)$ and $K_1(x)$ algorithms}

\subsection{Evaluation of asymptotic expansions}\label{algorithmic_asymptotic_expansions}

\subsection{Numerical integration}\label{algorithmic_numerical_integration}

Approximation $W_{-1}(z)$ with maximum relative error of $3.5e{-3}$ presented in \cite{Barry2004}
\begin{equation}
W_{-1}(z) \approx \log(-z) - \frac{2}{a} \left(1 - \left(1 + a \sqrt{-\frac{1 + \log(-z)}{2}}\right)^{-1}\right), \quad	a = 0.3205.
\end{equation}


\begin{itemize}
\item Estimate $h$
\item Estimate number of iteration by level. Using $W_{-1}(x)$.
\end{itemize}

TODO: describe algorithm and reference. Use of approximation for Lambert W function and references.

Mention the numerical integration method implemented in other libraries where the NIG distribution is available.

\subsubsection{Comparison complementary error function algorithms}


\subsection{Implementation}\label{subsection_implementation}

Decision tree. Machine Learning approach. Some details about ML model are out of the scope. The optimal regimes of applicability of the different series and asymptotic expansion could be derived using the information provided by the bounds on their remainders. To decide which method should be used in each regime, one could formulate an optimization problem with two possible objectives, minimization of terms (series complexity) and maximize robustness / reliability, or a blended approach (multi-objective optimization). 
The achievable accuracy of each method can be effectively estimated by developing rigorous error bounds. In the absence of error bounds (or if the computation is too involved) linear search with a rough estimate (more adequate for asymptotic expansions). PhD thesis section 2.3.2.

Given the computational cost of choosing the optimal method, in practice, a set of rules (logical expressions) generating a suboptimal solution might suffice. Our approach consists of generating a dataset covering small
and large regions of the parameters' domain and training a Machine Learning model to decide the regions where a method can obtain results with absolute relative error below tolerance. As a refinement, we simplify the model using a decision tree and rounding the boundaries. The result of the process are the algorithms 1-3.

Numerical integration: dominant method, it is used as a backup method whenever series expansions and asymptotic expansions do not converge.

General: comment on the complexity difference between the Hermite and Binomial series. Same $O(n^2)$ order by different leading factors.
Add note: similar number of terms according to table series [ref]. Estimate ratio function between complexities.
Quadratic (approximated shape. Could we use symbolic regression?? EXTRA)

We relax tolerance constraints to reduce the use of numerical integration (the most robust and accurate method) with the goal of improving performance. Numerical integration can be up to 200 times slower than most of the derived series expansions.

\subsubsection{Case $\beta = 0$}


{\centering
\begin{minipage}{.8\linewidth}
  \begin{algorithm}[H]
  \caption{Algorithm for special case $\beta = 0$, $F(x; \alpha, 0, \mu, \delta)$}\label{alg:case_beta_eq_zero}
\begin{algorithmic}
\Require $x \in \mathbb{R}$, $\alpha > 0$, $\mu \in \mathbb{R}$, $\delta > 0$
\Ensure $F(x; \alpha, 0, \mu, \delta)$
\State $C_1$ = $|x-\mu| \le 5$ and $\alpha / \omega \le 0.25$ and $\delta/2 \ge |x-\mu| $
\State $C_2$ = $(x-\mu)^2 \le 1.25$ and $\alpha / \omega \le 1$
\If{($C_1$ or $C_2$) and $\delta \ge 1$}
    \State series expansion \eqref{expansion_xmu_b0_positive}
\ElsIf{$(x-\mu)^2 \le 2.5$ and $\alpha \ge 5$ and $\delta \ge 10$ and $\delta \alpha \ge 200$}
    \State uniform asymptotic expansion \eqref{uniform_expansion_a_large}
\ElsIf{$(x-\mu)^2 \ge 70$ and $\alpha / \omega \ge 1$}
    \State asymptotic expansion \eqref{asymptotic_expansion_xmu_b0}
\Else
	\State numerical integration \eqref{truncated_integral}
\EndIf
\end{algorithmic}
  \end{algorithm}
\end{minipage}
\par
}

\subsubsection{Case $x = \mu$}

{\centering
\begin{minipage}{.85\linewidth}
  \begin{algorithm}[H]
  \caption{Algorithm for special case $x=\mu$, $F(\mu; \alpha, \beta, \mu, \delta)$}\label{alg:case_x_eq_mu}
\begin{algorithmic}
\Require $x \in \mathbb{R}$, $\alpha > 0$, $0 \le |\beta| < \alpha$, $\delta > 0$
\Ensure $F(\mu; \alpha, \beta, \mu, \delta)$
\If{$\alpha \le 10$ and $\delta \le 10$ and $|\beta| \le 1.5$ and $|\beta| / \alpha \le 0.9$}
    \State series expansion \eqref{series_x=mu_2}
\ElsIf{$|\beta| / \alpha \ge 0.75$ and $\delta \alpha \ge 300$ and $\delta \ge 15$}
    \State uniform asymptotic expansion \eqref{expansion_x_eq_mu_large_delta}
\Else
	\State numerical integration \eqref{truncated_integral}
\EndIf
\end{algorithmic}
  \end{algorithm}
\end{minipage}
\par
}

\subsubsection{General case}

{\centering
\begin{minipage}{.85\linewidth}
  \begin{algorithm}[H]
  \caption{Algorithm for $F(x; \alpha, \beta, \mu, \delta)$}\label{alg:case_general}
\begin{algorithmic}
\Require $x \in \mathbb{R}$, $\alpha > 0$, $0 \le |\beta| < \alpha$, $\mu \in \mathbb{R}$, $\delta > 0$
\Ensure $F(x; \alpha, \beta, \mu, \delta)$
\If{($|\beta| \le 1$ and $\gamma \ge 1.5$) or ($|\beta| \le 0.5$ and $\gamma \ge 0.75$)}
    \State series expansion \eqref{general_beta_small_hermite_series}
\ElsIf{$(x-\mu)^2 \le 2.25$ and $\delta \ge 2.5$}
    \State series expansion \eqref{general_xmu_small_hermite_series}
\ElsIf{$(x-\mu)^2 \le 3$ and $\delta \ge 1$ and $|\beta| \le 1.5$ and $\gamma \ge 0.75$}
	\State series expansion \eqref{general_expansion_xmu_small_bessel}
\ElsIf{$(x-\mu)^2 \le 20$ and $\alpha \ge 5$ and $|\beta| / \alpha \ge 0.5$ and $\delta \ge 15$}
	\State asymptotic expansion \eqref{general_asymptotic_delta}
\ElsIf{$(x-\mu)^2 \ge 100$ and $\alpha / \omega \ge 0.25$ and $\gamma \ge 10$ and $\delta \le 10$ and $\alpha / |\beta| \ge 5$}
	\State asymptotic expansion \eqref{general_asymptotic_xmu}
\Else
	\State numerical integration \eqref{truncated_integral}
\EndIf
\end{algorithmic}
  \end{algorithm}
\end{minipage}
\par
}

\section{Numerical experiments}

Publicly available implementations of the normal inverse Gaussian distribution are scarce. For example, this statistical distribution is not included in widely used numerical libraries such as Boost [ref], GNU Scientific Library (GSL) [ref] or CERN ROOT [ref] to mention a few. To the author knowledge the two exceptions are SciPy \texttt{stats.norminvgauss} [ref] and R packages \texttt{GeneralizedHyperbolic} [ref]. The implementation of the cumulative distribution function in both libraries is based on the use of numerical integration. SciPy performs direct computation via adaptive gaussian quadrature [ref - scipy docs]. \texttt{GeneralizedHyperbolic} partitions the real line into multiple regions and the numerical integration routine in used in each to integrate the density function. R integrate performs adaptive quadrature of univariate functions [QUADPACK ref]\footnote{https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/integrate}.


Define hard instance: cases where mpmath does not converge performing computation using 100 digits of precision. These cases are recomputed increasing the precision to 300 digits. Define symbol '-' meaning. Mention an alternative open-source library for arbitrary-precision calculation (arb) to double-check. Mathematica does not seem an option. In addition, using SciPy with double-precision arithmetic serves for time comparison purposes. 
Hard instances. Cases where mpmath does not converge requiring 100 digits of precision. We increase to 300 digits. Success: absolute relative error $< 5\cdot 10^{-13}$. '-' errors $> 10^{-10}$. Python using ctypes, comparable to SciPy using quad integration. Operating system and processor.

For each special case: show the definition of small and large instances. Bullet points, for each parameter. General comments about the need to resort to numerical integration for multiple cases. 

It might be worth taking as an example the value of x to be evaluated when computing the quantile at 0.99, 0.999, 0.9999. It might happen that the values (x-mu) are generally small, so the series expansions will be more frequently used for these cases.

\begin{itemize}
\item Running Linux Ubuntu 24.04 via WSL | AMD processor.
\item  Implementation in C++17 (standard supporting bessel, check if C++11 would be fine).
\item  Introduce SciPy implementation: adaptive quadrature Fortran code. For a fair time comparison, we run the
experiments from Python, calling the compiled library using ctypes.
\item  C++ optimization flags.
\end{itemize}


Overall comments:
\begin{itemize}
\item Double-exponential implementation faster and more robust than adaptive quadrature.
\item  Describe R libraries implementation: also based on adaptive quadrature. Similar algorithm.
\item  An implementation solely based on numerical integration is possible, but on various regimes the use
of series and asymptotic expansion can reliably complement with benefits in terms of CPU times.
\item  The cdf quickly goes to 0/1 for large values of |x-mu|. The mpmath library requires additional precision for
convergence in that regime, and the SciPy library struggles, returning incorrect values.
\item  Taking examples from various papers, state the common configurations in finance/energy modelling. Ideally,
these cases can he handled by one or various of the proposed expansions. e.g., Log returns
\end{itemize}

\subsection{Case $\beta = 0$}

\begin{table}[H]
\centering
\scalebox{0.9}
{
	\begin{tabular}{c|ccccc}
	\hline
	Region & $x$ & $\alpha$ & $\mu$ & $\delta$\\
	\hline	
	small & (-5, 5) & (0.001, 5) & (-5, 5) & (0.001, 5)\\
	large & (-10, 10) & (0.001, 50) & (-10, 10) & (0.001, 50)\\
	\hline	
	\end{tabular}
}
\caption{Case $\beta = 0$: Parameter range for small and large region.}
	\label{table_parameters_case_beta_eq_zero}
\end{table}


\begin{table}[H]
	\centering
	\scalebox{0.9}{
\begin{tabular}{ccccc|cc}
\hline
Library & Region & Success & Median & Mean & Time (s) & Time ($\mu s$)\\
\hline
SciPy & Small & 3952 / 5000 (79.04\%) &  $9.44\cdot 10^{-16}$ & $9.90 \cdot 10^{-4}$ & 2.45 & 490\\
Paper & Small & 4988 / 5000 (99.76\%) & $2.66\cdot 10^{-15}$ & $1.53\cdot 10^{-14}$ & 0.11 & 21\\
	\hline\
SciPy & Large & 3549 / 4868 (72.90\%) & $1.49\cdot 10^{-14}$ & $5.63\cdot 10^{-3}$ & 2.60 & 535\\
Paper & Large & 4868 / 4868 (100\%) & $1.11\cdot 10^{-15}$ & $1.27\cdot 10^{-14}$ & 0.22 & 45\\
	\hline\
SciPy & Large (hard) & 25 / 132 (18.94\%) & $1.44\cdot 10^{-4}$ & $6.45\cdot 10^{-3}$ & 0.028 & 214\\
Paper & Large (hard) & 127 / 132 (96.21\%) & $2.46\cdot 10^{-14}$ & $8.84\cdot 10^{-14}$ & 0.002 & 12\\
	\hline
	\end{tabular}}
	\caption{Comparison on the number of terms to achieve machine precision with the three series expansions for $|x-\mu| \to 0$.}
	\label{table_comparison_case_beta_eq_zero}
\end{table}


\begin{table}[H]
	\centering
	\scalebox{0.9}{
\begin{tabular}{ccccccc}
\hline
Method & Count & min & 25\% & Median & 75\% & max\\
\hline
Integration \eqref{truncated_integral} & 4121 (82.42\%) & 0 & $1.22\cdot 10^{-15}$ & $4.15\cdot 10^{-15}$ & $1.44\cdot 10^{-14}$ & $8.40\cdot 10^{-13}$\\
Series \eqref{expansion_xmu_b0_positive} & 879 (17.58\%) & 0 & 0 & $2.22\cdot 10^{-16}$ & $1.11\cdot 10^{-15}$ & $6.58\cdot 10^{-14}$\\
	\hline
	\end{tabular}}
	\caption{Precision metrics of the numerical methods used for computing in the small region. The errors are the absolute relative errors compared to the reference solutions obtained using mpmath. Percentiles: 25, 50 (median), 75.}
	\label{table_methods_case_beta_eq_zero_small}
\end{table}

\begin{table}[H]
	\centering
	\scalebox{0.9}{
\begin{tabular}{ccccccc}
\hline
Method & Count & min & 25\% & Median & 75\% & max\\
\hline
Integration \eqref{truncated_integral} & 3137 (64.44\%) & 0 & $3.33\cdot 10^{-16}$ & $8.88\cdot 10^{-16}$ & $4.11\cdot 10^{-15}$ & $4.84\cdot 10^{-13}$\\
Series \eqref{expansion_xmu_b0_positive} & 810 (16.64\%) & 0 & $3.33\cdot 10^{-16}$ & $1.33\cdot 10^{-15}$ & $8.41\cdot 10^{-15}$ & $4.28\cdot 10^{-13}$\\
Asymptotic \eqref{asymptotic_expansion_xmu_b0} & 620 (12.74\%) & 0 & 0 & 0 & $2.54\cdot 10^{-14}$ & $2.31\cdot 10^{-13}$\\
Asymptotic \eqref{uniform_expansion_a_large} & 301 (6.18\%) & $2.22\cdot 10^{-16}$ & $4.44\cdot 10^{-15}$ & $1.24\cdot 10^{-14}$ & $3.46\cdot 10^{-14}$ & $2.26\cdot 10^{-13}$\\
	\hline
	\end{tabular}}
	\caption{Precision metrics of the numerical methods used for computing in the large region. The errors are the absolute relative errors compared to the reference solutions obtained using mpmath. Percentiles: 25, 50 (median), 75.}
	\label{table_methods_case_beta_eq_zero_large}
\end{table}

\begin{table}[H]
	\centering
	\scalebox{0.9}{
\begin{tabular}{ccccccc}
\hline
Method & Count & min & 25\% & Median & 75\% & max\\
\hline
Integration \eqref{truncated_integral} & 22 (16.67\%) & 0 & $6.94\cdot 10^{-16}$ & $3.66\cdot 10^{-15}$ & $1.76\cdot 10^{-15}$ & $5.98\cdot 10^{-14}$\\
Series \eqref{expansion_xmu_b0_positive} & 7 (5.30\%) & $4.44\cdot 10^{-16}$ & $6.11\cdot 10^{-16}$ & $2.00\cdot 10^{-15}$ & $5.39\cdot 10^{-13}$ & $3.22\cdot 10^{-12}$\\
Asymptotic \eqref{asymptotic_expansion_xmu_b0} & 100 (75.76\%) & $8.88\cdot 10^{-16}$ & $1.35\cdot 10^{-14}$ & $3.00\cdot 10^{-14}$ & $5.57\cdot 10^{-14}$ & $1.30\cdot 10^{-13}$\\
Asymptotic \eqref{uniform_expansion_a_large} & 3 (2.27\%) & $5.76\cdot 10^{-13}$ & $8.84\cdot 10^{-13}$ & $1.19\cdot 10^{-12}$ & $1.42\cdot 10^{-12}$ & $1.64\cdot 10^{-12}$\\
	\hline
	\end{tabular}}
	\caption{Precision metrics of the numerical methods used for computing in the large (hard) region. The errors are the absolute relative errors compared to the reference solutions obtained using mpmath. Percentiles: 25, 50 (median), 75.}
	\label{table_methods_case_beta_eq_zero_large}
\end{table}


\subsection{Case $x = \mu$}

\begin{table}[H]
\centering
\scalebox{0.9}
{
	\begin{tabular}{c|cccc}
	\hline
	Region & $\alpha$ & $\beta$ & $\delta$\\
	\hline	
	small & (0.001, 5) & (-5, 5) & (0.001, 5)\\
	large & (0.001, 50) & (-50, 50) & (0.001, 50)\\
	\hline	
	\end{tabular}
}
\caption{Case $x = \mu$: Parameter range for small and large region.}
	\label{table_parameters_case_x_eq_mu}
\end{table}

\begin{table}[H]
	\centering
	\scalebox{0.9}{
\begin{tabular}{ccccc|cc}
\hline
Library & Region & Success & Median & Mean & Time (s) & Time ($\mu s$)\\
\hline
SciPy & Small & 4838 / 5000 (96.76\%) &  $8.88\cdot 10^{-16}$ & $8.40 \cdot 10^{-11}$ & 2.02 & 405\\
Paper & Small & 5000 / 5000 (100\%) & $2.22\cdot 10^{-16}$ & $9.60\cdot 10^{-16}$ & 0.03 & 7\\
	\hline\
SciPy & Large & 3084 / 4548 (67.81\%) & $1.96\cdot 10^{-15}$ & $1.34\cdot 10^{-12}$ & 2.58 & 516\\
Paper & Large & 4548 / 4548 (100\%) & $6.66\cdot 10^{-16}$ & $8.25\cdot 10^{-15}$ & 0.27 & 53\\
	\hline\
SciPy & Large (hard) & 8 / 452 (1.77\%) & $1.26\cdot 10^{-1}$ & $1.65\cdot 10^{-1}$ & 0.104 & 229\\
Paper & Large (hard) & 425 / 452 (94.03\%) & $3.86\cdot 10^{-14}$ & $2.47\cdot 10^{-12}$ & 0.024 & 53\\
	\hline
	\end{tabular}}
	\caption{Comparison on the number of terms to achieve machine precision with the three series expansions for $|x-\mu| \to 0$.}
	\label{table_comparison_case_x_eq_mu}
\end{table}

\begin{table}[H]
	\centering
	\scalebox{0.9}{
\begin{tabular}{ccccccc}
\hline
Method & Count & min & 25\% & Median & 75\% & max\\
\hline
Integration \eqref{truncated_integral} & 949 (18.48\%) & 0 & 0 & $2.22\cdot 10^{-16}$ & $4.44\cdot 10^{-16}$ & $6.00\cdot 10^{-15}$\\
Series \eqref{series_x=mu_2} & 4051 (81.02\%) & 0 & 0 & $2.22\cdot 10^{-16}$ & $5.55\cdot 10^{-16}$ & $2.48\cdot 10^{-13}$\\
	\hline
	\end{tabular}}
	\caption{Precision metrics of the numerical methods used for computing in the small region. The errors are the absolute relative errors compared to the reference solutions obtained using mpmath. Percentiles: 25, 50 (median), 75.}
	\label{table_methods_case_x_eq_mu_small}
\end{table}

\begin{table}[H]
	\centering
	\scalebox{0.9}{
\begin{tabular}{ccccccc}
\hline
Method & Count & min & 25\% & Median & 75\% & max\\
\hline
Integration \eqref{truncated_integral} & 4289 (94.31\%) & 0 & $2.22\cdot 10^{-16}$ & $5.55\cdot 10^{-16}$ & $3.77\cdot 10^{-15}$ & $4.81\cdot 10^{-13}$\\
Series \eqref{series_x=mu_2} & 126 (2.77\%) & 0 & $2.22\cdot 10^{-16}$ & $4.44\cdot 10^{-16}$ & $1.67\cdot 10^{-15}$ & $2.60\cdot 10^{-13}$\\
Asymptotic \eqref{expansion_x_eq_mu_large_delta} & 133 (2.92\%) & $5.55\cdot 10^{-16}$ & $1.70\cdot 10^{-14}$ & $2.70\cdot 10^{-14}$ & $4.30\cdot 10^{-14}$ & $1.15\cdot 10^{-13}$\\
	\hline
	\end{tabular}}
	\caption{Precision metrics of the numerical methods used for computing in the large region. The errors are the absolute relative errors compared to the reference solutions obtained using mpmath. Percentiles: 25, 50 (median), 75.}
	\label{table_methods_case_x_eq_mu_large}
\end{table}

\begin{table}[H]
	\centering
	\scalebox{0.9}{
\begin{tabular}{ccccccc}
\hline
Method & Count & min & 25\% & Median & 75\% & max\\
\hline
Integration \eqref{truncated_integral} & 204 (45.13\%) & $2.22\cdot 10^{-16}$ & $1.73\cdot 10^{-14}$ & $3.22\cdot 10^{-14}$ & $4.73\cdot 10^{-14}$ & $1.19\cdot 10^{-13}$\\
Series \eqref{series_x=mu_2} & 1 (0.22\%) & $7.76\cdot 10^{-13}$ & $7.76\cdot 10^{-13}$ & $7.76\cdot 10^{-13}$ & $7.76\cdot 10^{-13}$ & $7.76\cdot 10^{-13}$\\
Asymptotic \eqref{expansion_x_eq_mu_large_delta} & 247 (54.65\%) & 0 & $3.09\cdot 10^{-14}$ & $5.43\cdot 10^{-14}$ & $9.60\cdot 10^{-14}$ & $-$\\
	\hline
	\end{tabular}}
	\caption{Precision metrics of the numerical methods used for computing in the large (hard) region. The errors are the absolute relative errors compared to the reference solutions obtained using mpmath. Percentiles: 25, 50 (median), 75.}
	\label{table_methods_case_x_eq_mu_large}
\end{table}


\subsection{General case}

TODO: add special section where only integration is used. This is needed since the proposed algorithm is not that reliable compared to those described for special cases.

\begin{table}[H]
\centering
\scalebox{0.9}
{
	\begin{tabular}{c|cccccc}
	\hline
	Region & $x$ & $\alpha$ & $\beta$ & $\mu$ & $\delta$\\
	\hline	
	small & (-5, 5) & (0.001, 5) & (-5, 5) & (-5, 5) & (0.001, 5)\\
	large & (-10, 10) & (0.001, 50) & (-50, 50) & (-10, 10) & (0.001, 50)\\
	\hline	
	\end{tabular}
}
\caption{General case: Parameter range for small and large region.}
	\label{table_parameters_case_general}
\end{table}

\begin{table}[H]
	\centering
	\scalebox{0.9}{
\begin{tabular}{ccccc|cc}
\hline
Library & Region & Success & Median & Mean & Time (s) & Time ($\mu s$)\\
\hline
SciPy & Small & 3983 / 5000 (79.66\%) &  $1.78\cdot 10^{-15}$ & $1.89 \cdot 10^{-5}$ & 2.53 & 506\\
Paper & Small & 4939 / 5000 (98.78\%) & $3.89\cdot 10^{-15}$ & $1.01\cdot 10^{-13}$ & 0.12 & 24\\
	\hline\
SciPy & Large & 2949 / 4296 (68.65\%) & $4.49\cdot 10^{-14}$ & $7.91\cdot 10^{-3}$ & 2.79 & 559\\
Paper & Large & 4296 / 4296 (100\%) & $6.66\cdot 10^{-16}$ & $1.09\cdot 10^{-14}$ & 0.44 &88\\
	\hline\
SciPy & Large (hard) & 70 / 704 (9.94\%) & $0.16\cdot 10^{-1}$ & $*$ & 0.16 & 223\\
Paper & Large (hard) & 409 / 704 (58.10\%) & $8.07\cdot 10^{-14}$ & $*$ & 0.07 & 95\\
	\hline
	\end{tabular}}
	\caption{Comparison on the number of terms to achieve machine precision with the three series expansions for $|x-\mu| \to 0$. $*$: infinity.}
	\label{table_comparison_case_general}
\end{table}

\begin{table}[H]
	\centering
	\scalebox{0.9}{
\begin{tabular}{ccccccc}
\hline
Method & Count & min & 25\% & Median & 75\% & max\\
\hline
Integration \eqref{truncated_integral} & 3585 (71.70\%) & 0 & $6.66\cdot 10^{-16}$ & $5.00\cdot 10^{-15}$ & $1.78\cdot 10^{-14}$ & $7.56\cdot 10^{-11}$\\
Series \eqref{general_expansion_xmu_small_bessel} & 212 (4.24\%) & 0 & $4.44\cdot 10^{-16}$ & $1.61\cdot 10^{-15}$ & $1.14\cdot 10^{-14}$ & $2.68\cdot 10^{-12}$\\
Series \eqref{general_xmu_small_hermite_series} & 606 (12.12\%) & 0 & $3.33\cdot 10^{-16}$ & $8.88\cdot 10^{-16}$ & $5.30\cdot 10^{-15}$ & $3.08\cdot 10^{-11}$\\
Series \eqref{general_beta_small_hermite_series} & 597 (11.94\%) & 0 & $8.88\cdot 10^{-16}$ & $4.22\cdot 10^{-15}$ & $1.47\cdot 10^{-14}$ & $1.70\cdot 10^{-12}$\\
	\hline
	\end{tabular}}
	\caption{Precision metrics of the numerical methods used for computing in the small region. The errors are the absolute relative errors compared to the reference solutions obtained using mpmath. Percentiles: 25, 50 (median), 75.}
	\label{table_methods_case_general_small}
\end{table}

\begin{table}[H]
	\centering
	\scalebox{0.9}{
\begin{tabular}{ccccccc}
\hline
Method & Count & min & 25\% & Median & 75\% & max\\
\hline
Integration \eqref{truncated_integral} & 3344 (77.84\%) & 0 & $2.22\cdot 10^{-16}$ & $7.77\cdot 10^{-16}$ & $5.19\cdot 10^{-15}$ & $4.54\cdot 10^{-13}$\\
Series \eqref{general_expansion_xmu_small_bessel} & 9 (0.21\%) & $2.22\cdot 10^{-16}$ & $1.11\cdot 10^{-15}$ & $2.00\cdot 10^{-15}$ & $1.09\cdot 10^{-14}$ & $1.46\cdot 10^{-13}$\\
Series \eqref{general_xmu_small_hermite_series} & 516 (12.01\%) & 0 & $2.22\cdot 10^{-16}$ & $6.66\cdot 10^{-16}$ & $8.83\cdot 10^{-15}$ & $4.90\cdot 10^{-13}$\\
Series \eqref{general_beta_small_hermite_series} & 156 (3.63\%) & 0 & $4.44\cdot 10^{-16}$ & $2.33\cdot 10^{-15}$ & $1.87\cdot 10^{-14}$ & $4.71\cdot 10^{-13}$\\
Asymptotic \eqref{general_asymptotic_xmu} & 13 (0.30\%) &  0 & 0 & 0 & 0 & $2.11\cdot 10^{-14}$\\
Asymptotic \eqref{general_asymptotic_delta} & 258 (6.01\%) &  0 & 0 & 0 & 0 & $3.62\cdot 10^{-13}$\\
	\hline
	\end{tabular}}
	\caption{Precision metrics of the numerical methods used for computing in the small region. The errors are the absolute relative errors compared to the reference solutions obtained using mpmath. Percentiles: 25, 50 (median), 75.}
	\label{table_methods_case_general_large}
\end{table}


\begin{table}[H]
	\centering
	\scalebox{0.9}{
\begin{tabular}{ccccccc}
\hline
Method & Count & min & 25\% & Median & 75\% & max\\
\hline
Integration \eqref{truncated_integral} & 400 (56.82\%) & $2.22\cdot 10^{-15}$ & $2.75\cdot 10^{-14}$ & $4.76\cdot 10^{-14}$ & $7.70\cdot 10^{-14}$ & $-$ \\
Series \eqref{general_expansion_xmu_small_bessel} & 2 (0.29\%) & $9.32\cdot 10^{-13}$ & $1.67\cdot 10^{-11}$ & $3.24\cdot 10^{-11}$ & $4.81\cdot 10^{-11}$ & $6.81\cdot 10^{-11}$\\
Series \eqref{general_xmu_small_hermite_series} & 155 (22.02\%) & $9.99\cdot 10^{-16}$ & $1.11\cdot 10^{-12}$ & $3.75\cdot 10^{-10}$ & $-$ & $-$\\
Series \eqref{general_beta_small_hermite_series} & 13 (1.85\%) & $2.55\cdot 10^{-13}$ & $7.09\cdot 10^{-13}$ & $1.62\cdot 10^{-12}$ & $7.45\cdot 10^{-12}$ & $7.96\cdot 10^{-11}$\\
Asymptotic \eqref{general_asymptotic_xmu} & 14 (1.99\%) & $2.66\cdot 10^{-15}$ & $5.22\cdot 10^{-14}$ & $3.65\cdot 10^{-12}$ & $2.08\cdot 10^{-10}$ & $-$\\
Asymptotic \eqref{general_asymptotic_delta} & 120 (17.05\%) & $2.11\cdot 10^{-15}$ & $3.87\cdot 10^{-13}$ & $1.02\cdot 10^{-9}$ & $-$ & $-$\\
	\hline
	\end{tabular}}
	\caption{Precision metrics of the numerical methods used for computing in the small region. The errors are the absolute relative errors compared to the reference solutions obtained using mpmath. Percentiles: 25, 50 (median), 75.}
	\label{table_methods_case_general_large}
\end{table}

\begin{table}[H]
	\centering
	\scalebox{0.9}{
\begin{tabular}{ccccc|cc}
\hline
Library & Region & Success & Median & Mean & Time (s) & Time ($\mu s$)\\
\hline
SciPy & Small & 3983 / 5000 (79.66\%) &  $1.78\cdot 10^{-15}$ & $1.89 \cdot 10^{-5}$ & 2.53 & 506\\
Paper & Small & 4980 / 5000 (99.60\%) & $3.99\cdot 10^{-15}$ & $1.64\cdot 10^{-14}$ & 0.12 & 27\\
	\hline\
SciPy & Large & 3139 / 5000 (62.78\%) & $0.16\cdot 10^{-1}$ & $*$ & 2.74 & 550\\
Paper & Large & 4964 / 5000 (99.28\%) & $8.07\cdot 10^{-14}$ & $*$ & 0.51 & 102\\
	\hline
	\end{tabular}}
	\caption{Comparison on the number of terms to achieve machine precision with the three series expansions for $|x-\mu| \to 0$. $*$: infinity.}
	\label{table_comparison_case_general_integration}
\end{table}

\section{Conclusions}

\appendix
\section{The function $\Phi\left(\frac{a}{\sqrt{t}} + b\sqrt{t}\right)$}
In this section, we present some results to be used throughout this work.

The function $F(t; a, b) = \Phi\left(\frac{a}{\sqrt{t}} + b\sqrt{t}\right)$ is part of the integrand of the integral representation in \eqref{integral_phi}. Given its relevance throughout this work, we introduce here some results that shall be used subsequently. $F(t; a, b)$ has the following integral representation \cite[\S 7.7.6]{NIST:DLMF}
\begin{equation}\label{integral_erfc_ab}
F(t; a, b) = \frac{1}{2}\erfc\left(-\frac{\frac{a}{\sqrt{t}} + b\sqrt{t}}{\sqrt{2}}\right)  = \sqrt{\frac{t}{\pi}} e^{-\frac{a^2}{2t}} \int_{-b/\sqrt{2}}^{\infty} e^{-(tu^2 - \sqrt{2}au)} \mathop{du}
\end{equation}

\subsection{Expansions $t$}

\subsubsection{Expansion $t \to 0$}

Let us consider the case $a < 0$, since we can use the mirror property $\Phi(z) = 1 - \Phi(-z)$ otherwise. To obtain an expansion for $t \to 0$, we expand $e^{-tu^2}$ and interchange summation and integration obtaining
\begin{equation*}
F(t; a, b) = \sqrt{\frac{t}{\pi}} e^{-\frac{a^2}{2t}} \sum_{k=0}^{\infty} \frac{(-t)^k}{k!}\int_{-b/\sqrt{2}}^{\infty} e^{\sqrt{2}a u} u^{2k}\mathop{du}.
\end{equation*}
For $a < 0$ the integral can be expressed in closed form in terms of the incomplete gamma function, $\Gamma(a, x)$
\begin{equation*}
\int_{-b/\sqrt{2}}^{\infty} e^{\sqrt{2}a u} u^{2k}\mathop{du} = \frac{\Gamma(2k+1, -ab)}{(\sqrt{2}a)^{2k+1}},
\end{equation*}
and for the special case $b=0$, it reduces to
\begin{equation*}
\int_{0}^{\infty} e^{\sqrt{2}a u} u^{2k}\mathop{du} = \frac{\Gamma(2k+1)}{(\sqrt{2}a)^{2k+1}}.
\end{equation*}
Then, we obtain the series expansion valid for $t \to 0$, $a \to -\infty$ and fixed $b$
\begin{equation}\label{phi_expansion_incgamma_t_small}
F(t; a, b) = \sqrt{\frac{t}{\pi}} e^{-\frac{a^2}{2t}} \sum_{k=0}^{\infty} \frac{(-1)^{k+1} t^k}{k!}\frac{\Gamma(2k + 1, ab)}{(\sqrt{2}a)^{2k+1}}.
\end{equation}

NOTE: same expansion as $\erfc(x), x \to \infty$.

Moreover, another expansion valid for large values of $a > 0$ and $b > 0$ can be obtained after expanding $F(t;a,b)$ at $t=0$. The first coefficients are
\begin{equation}
c_0 = \frac{1}{a}, \quad c_1 = \frac{ab + 1}{a^3}, \quad c_2 = \frac{a^2b² +3ab + 3}{a^5}, \quad c_3 = \frac{a^3b^3 + 6a^2b^3 + 15ab + 15}{a^7}
\end{equation}
and the expansion reads
\begin{equation}
F(t; a, b) = 1 + \frac{e^{-\frac{1}{2} \left(\frac{a}{\sqrt{t}} + b\sqrt{t} \right)^2}}{\sqrt{2\pi}}\sum_{k=0}^{\infty}(-1)^{k+1}c_k t^{k + \frac{1}{2}}.
\end{equation}
The coefficients are expressible in terms of Bessel polynomials $y_k(x)$ \cite[\S A001498]{OEIS}, and it follows that
\begin{equation}
F(t; a, b) = 1 + \frac{e^{-\frac{1}{2} \left(\frac{a}{\sqrt{t}} + b\sqrt{t} \right)^2}}{a\sqrt{2\pi}}\sum_{k=0}^{\infty}(-1)^{k+1} \left(\frac{b}{a}\right)^k y_k\left(\frac{1}{ab}\right) t^{k + \frac{1}{2}},
\end{equation}
where $y_k(x)$ has an explicit formula
\begin{equation}
y_k(x) = \sum_{m=0}^k \binom{k}{m} (k + 1)_m \left(\frac{x}{2}\right)^m.
\end{equation}

Using the connection of the Bessel polynomials with the modified Bessel function of the second kind $K_k(x)$ given by \cite[\S 33.1.3]{Temme2015}
\begin{equation}
y_k(x) = \sqrt{\frac{2}{\pi x}}e^{1/x} K_{k + \frac{1}{2}}\left(\frac{1}{x}\right),
\end{equation}
the resulting expansion is represented as a Bessel-type expansion
\begin{equation}\label{phi_expansion_besselk}
F(t; a, b) = 1 + \frac{e^{-\frac{a^2}{2t} - \frac{b^2}{2}t}}{\pi}\sqrt{\frac{b}{a}}\sum_{k=0}^{\infty} (-1)^{k+1} \left(\frac{b}{a}\right)^k K_{k + \frac{1}{2}}(ab)t^{k + \frac{1}{2}}.
\end{equation}
The expansion is convergent for $t < 1$. The convergence follows from the asymptotic estimate of $(b/a)^k K_k(ab) \sim (b/a)^k \sqrt{\frac{\pi}{2ab}}e^{-ab}$ as $|ab| \to \infty$. The expansion can be seen as an asymptotic expansion for large $a$, or as a uniform asymptotic expansion for $a \sim b$. The coefficients can be computed by using a recurrence relation for the modified Bessel function.

\subsubsection{Expansion $t \to \infty$}

Let us focus on the case $t \to \infty$. We can develop an asymptotic expansion after expanding the term $e^{\sqrt{2}au}$ in \eqref{integral_erfc_ab}, which yields
\begin{equation*}
F(t; a, b) = \sqrt{\frac{t}{\pi}} e^{-\frac{a^2}{2t}} \sum_{k=0}^{\infty}\frac{(\sqrt{2}a)^k}{k!}\int_{-b/\sqrt{2}}^{\infty} e^{-t u^2} u^k \mathop{du}.
\end{equation*}
Considering the case $b < 0$ (again, we can use the mirror property), the integral has a closed-form
\begin{equation*}
\int_{-b/\sqrt{2}}^{\infty} e^{-t u^2} u^k \mathop{du} = \frac{\Gamma\left(\frac{k+1}{2}, \frac{b^2}{2}t\right)}{2 t^{\frac{k+1}{2}}}.
\end{equation*}
Thus,
\begin{equation}\label{phi_expansion_incgamma}
F(t; a, b) = \sqrt{\frac{t}{\pi}} \frac{e^{-\frac{a^2}{2t}}}{2}  \sum_{k=0}^{\infty}\frac{(\sqrt{2}a)^k}{k!} \frac{\Gamma\left(\frac{k+1}{2}, \frac{b^2}{2}t\right)}{t^{\frac{k+1}{2}}}.
\end{equation}
The asymptotic behaviour of the terms in the series is
\begin{equation*}
\frac{\Gamma\left(\frac{k+1}{2}, \frac{b^2}{2}t\right)}{t^{\frac{k+1}{2}}} \sim \left(\frac{b^2}{2}\right)^{\frac{k+1}{2}} e^{-\frac{b^2}{2} t}, \quad t\to\infty.
\end{equation*}
In fact this series is convergent, as can be observed taking the asymptotic estimate of $\Gamma(k, x)$ as $k \to \infty$. A simpler convergent expansion can be obtained transforming the integral in \eqref{integral_erfc_ab}
\begin{equation*}
\sqrt{\frac{t}{\pi}} e^{-\frac{a^2}{2t}} \int_{-b/\sqrt{2}}^{\infty} e^{-(tu^2 - \sqrt{2}au)} \mathop{du} = \sqrt{\frac{t}{\pi}} e^{-\frac{a^2}{2t} -ab - \frac{b^2}{2}t}\int_0^{\infty}e^{\sqrt{2}(a+bt)u} e^{-tu^2}\mathop{dt},
\end{equation*}
and expanding $e^{\sqrt{2}(a+bt)u}$ obtaining
\begin{equation}
F(t; a, b) = \sqrt{\frac{t}{\pi}} \frac{e^{-\frac{a^2}{2t} -ab - \frac{b^2}{2}t}}{2} \sum_{k=0}^{\infty} \frac{(\sqrt{2}(a+bt))^k}{k!}\frac{\Gamma\left(\frac{k+1}{2}\right)}{t^{\frac{k+1}{2}}}.
\end{equation}

Similarly to the expansion at $t \to 0$, we can obtain an asymptotic expansion expanding $F(t; a, b)$ at $t \to \infty$. For $b > 0$, the first terms of the expansion are
\begin{equation}
c_0 = 1, \quad c_1 = 2 + 2ab + a^2 b^2, \quad c_2 = 24 + 24ab + 12a^2b^2 + 4a^3b^3 + a^4b^4,
\end{equation}
\begin{equation}
F(t; a, b) = 1 + \frac{e^{-ab - \frac{b^2}{2}t}}{\sqrt{2\pi}}\sum_{k=0}^{\infty}\frac{(-1)^{k+1}}{2^k k!}\frac{c_k}{b^{2k+1}}\left(\frac{1}{t}\right)^{k+\frac{1}{2}}.
\end{equation}
The coefficients $c_k$ are expressible in terms of the incomplete gamma function, since
\begin{equation*}
c_k = \sum_{j=0}^{2k}\frac{(2k)!}{j!}(ab)^j = e^{ab}\Gamma(2k+1, ab).
\end{equation*}
Rearranging terms, we get
\begin{equation}\label{phi_expansion_at_inf}
F(t; a, b) = 1 + \frac{e^{- \frac{b^2}{2}t}}{\sqrt{2\pi}}\sum_{k=0}^{\infty}\frac{(-1)^{k+1}}{2^k k!}\frac{\Gamma(2k+1, ab)}{b^{2k+1}}\left(\frac{1}{t}\right)^{k+\frac{1}{2}}.
\end{equation}

\subsubsection{Expansion $t \to u$}

Lastly, we study the expansion of $F(t;a,b)$ at $t=u$. This expansion shall be crucial when developing various Bessel-type asymptotic expansions later on. The first coefficients of the Taylor series are
\begin{equation*}
c_0 = \Phi\left(\frac{a}{\sqrt{u}} + b\sqrt{u}\right)d_0,\quad c_1 = \phi\left(\frac{a}{\sqrt{u}} + b\sqrt{u}\right) d_1, \quad c_2 = -\phi\left(\frac{a}{\sqrt{u}} + b\sqrt{u}\right) d_2, \quad
c_3 = \phi\left(\frac{a}{\sqrt{u}} + b\sqrt{u}\right) d_3,
\end{equation*}
where
\begin{align*}
d_0 &= 1\\
d_1 &= \frac{-a + bu}{2u^{3/2}}\\
d_2 &=\frac{a^3 -3au -a^2 bu + bu^2 -ab^2 u^2 + b^3u^3}{8 u^{7/2}}\\
d_3 &= \frac{-a^5 +10a^3u + a^4bu -15au^2 - 6a^2bu^2 + 2a^3 b^2 u^2 +3bu^3 -6ab^2u^3 - 2a^2b^3 u^3 + 2b^3 u^4 -ab^4u^4 + b^5 u^5}{48 u^{11/2}},
\end{align*}
and $\phi(x) = \frac{e^{-x^2/2}}{\sqrt{2\pi}}$ is the probability density function of the standard normal distribution. Thus, we have
\begin{equation}\label{phi_expansion_at_u}
F(t; a, b) = \sum_{k=0}^{\infty} c_k (t-u)^k.
\end{equation}
Additional terms satisfy the following recurrence
\begin{equation}
c_{k+4} = \frac{f_0(k) c_k + f_1(k) c_{k+1} + f_2(k) c_{k+2} + f_3(k) c_{k+3}}{f_4(k)}, \quad k \ge 0
\end{equation}
where
\begin{align*}
f_0(k) &= -kb^3\\
f_1(k) &= -(1 + k) b (1 + 2k -ab + 3b^3u)\\
f_2(k) &= (2 + k)(5a + 2ka +a^2b - 8bu - 6kbu +2ab^2u -3b^3u^2)\\
f_3(k) &= -(3 + k)(a^3 - 11au -4kau - a^2bu + 13bu^2 + 6kbu^2 -ab^2u^2 + b^3 u^3)\\
f_4(k) &= 2 (3 + k) (4 + k) u^2 (-a + bu)
\end{align*}

\subsection{Expansion $a \to 0$}
We also consider expansions for small values of the parameters. If we expand $F(t; a, b)$ at $a = 0$, we obtain the series
\begin{equation}
F(t; a, b) = \Phi\left(b\sqrt{t}\right) + \frac{e^{-\frac{b^2 t}{2}}}{\sqrt{2\pi t}}\sum_{k=1}^{\infty} (-1)^{k+1} \frac{a^k P_{k-1}(t; b)}{k!}.
\end{equation}
The first coefficients $P_k(t; b)$ are
\begin{align*}
P_0(t; b) &= 1\\
P_1(t; b) &= b\\
P_2(t; b) &= \frac{b^2 t - 1}{t}\\
P_3(t; b) &= \frac{b^3 t - 3b}{t}\\
P_4(t; b) &= \frac{b^4 t^2 - 6b^2t + 3}{t^2}\\
P_5(t; b) &= \frac{b^5 t^2 - 10b^3 t + 15 b}{t^2}
\end{align*}
Looking at the first coefficients, it is not hard to observe that coefficients $P_k(t;b)$ are expressible in terms of probabilist Hermite polynomials. Thus, after using the connection formula between probabilist and classical Hermite polynomials, we obtain the following convergent series expansion
\begin{equation}\label{phi_expansion_a_small}
F(t; a, b) = \Phi\left(b\sqrt{t}\right) + \frac{e^{-\frac{b^2 t}{2}}}{\sqrt{2\pi t}} \sum_{k=0}^{\infty} \frac{(-1)^k a^{k+1}}{(k+1)!}\frac{1}{(2t)^{k/2}} H_k\left(k, b\sqrt{\frac{t}{2}}\right)
\end{equation}

\subsection{Expansion $b \to 0$}
The Hermite-type expansion for the case $b \to 0$ is obtained analogously after expanding $F(t; a, b)$ at $b=0$. Thus,
\begin{equation}\label{phi_expansion_b_small}
F(t; a, b) = \Phi\left(\frac{a}{\sqrt{t}}\right) + e^{-\frac{a^2 t}{2}}\sqrt{\frac{t}{2\pi}} \sum_{k=0}^{\infty}\frac{(-1)^k b^{k+1}}{(k + 1)!}\left(\frac{t}{2}\right)^{k/2} H_k\left(\frac{a}{\sqrt{2t}}\right).
\end{equation}

\section{The modified Bessel function of the second kind}
For small values of $x$ we have
\begin{equation}\label{besselk_x_to_0}
K_{\nu}(x) \sim \frac{2^{|\nu| - 1} \Gamma(|\nu|)}{x^{|\nu|}}, \quad x \to 0, \quad \nu \neq 0.
\end{equation}

Asymptotic behaviour with respect to the argument
\begin{equation}\label{besselk_x_to_inf}
K_{\nu}(x) \sim \sqrt{\frac{\pi}{2x}} e^{-x}, \quad x \to \infty, \quad \nu \in \mathbb{R}.
\end{equation}

Asymptotic behaviour with respect to the order
\begin{equation}\label{besselk_order_to_inf}
K_{\nu}(x) \sim \sqrt{\frac{\pi}{2\nu}}\left(\frac{ex}{2\nu}\right)^{-\nu}, \quad \nu \to \infty, \quad x \neq 0.
\end{equation}

The modified Bessel function can be stated explicitly for $\nu = n + 1/2$ with $n \in \mathbb{Z}$,
\begin{equation}\label{besselk_half}
K_{n + 1/2}(z) = \sqrt{\frac{\pi}{2z}} \sum_{j=0}^n \frac{(n + j)!}{j! (n-j)!} (2z)^{-j}e^{-z}, \quad z\in \mathcal{C}.
\end{equation}

\section{The incomplete gamma functions}\label{appendix_incomplete_gamma}

\begin{equation}
Q(a, x) = \frac{\Gamma(a, x)}{\Gamma(a)}
\end{equation}

\begin{equation}
P(a, x) = \frac{\gamma(a, x)}{\Gamma(a)}
\end{equation}

\begin{equation}
\Gamma(a, x) + \gamma(a, x) = \Gamma(a)
\end{equation}

\begin{equation}
P(a, x) + Q(a, x) = 1
\end{equation}

\begin{itemize}
\item Series for integer $a$
\item Recursions
\end{itemize}


When $a$ is a positive integer the incomplete gamma functions are given by a terminating series of the exponential function $e_n(z)$ \cite[\S 11]{Temme1996}
\begin{equation}
e_n(z) = \sum_{j=0}^n \frac{z^j}{j!}.
\end{equation}
For $n =0,1,\ldots,$
\begin{align}
\gamma(n + 1, z) &= n! \left[1 - e^{-z} e_n(z)\right]\\
\Gamma(n + 1, z) &= n! e^{-z} e_n(z)
\end{align}

\bibliographystyle{plain}
\bibliography{bib}

\end{document}
